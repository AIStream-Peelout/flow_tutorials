{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bFYerqNDtd4"
      },
      "source": [
        "from google.colab import auth\n",
        "from datetime import datetime\n",
        "auth.authenticate_user()\n",
        "!gsutil -m cp -r gs://predict_cfs/meta2 .\n",
        "!gsutil -m cp -r  gs://predict_cfs/meta3 .\n",
        "!gsutil -m cp -r  gs://predict_cfs/meta4 ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_4nVeCaFI0v"
      },
      "source": [
        "import torch\n",
        "class MetaDataEncoder(torch.nn.Module):\n",
        "  def __init__(self, number_meta_items, end_dimension, n_layers):\n",
        "    super().__init__()\n",
        "    self.number_meta_items = number_meta_items\n",
        "    self.end_dimension = end_dimension\n",
        "    self.linear_layer_array = []\n",
        "    for i in range(0, n_layers-1):\n",
        "      self.linear_layer_array.append(torch.nn.Linear(number_meta_items, number_meta_items))\n",
        "    self.final_layer = torch.nn.Linear(number_meta_items, end_dimension)\n",
        "    self.max_flow = torch.nn.Linear(end_dimension, 1)\n",
        "    self.min_flow = torch.nn.Linear(end_dimension, 1)\n",
        "  def forward(self, x):\n",
        "    for layer in self.linear_layer_array:\n",
        "      x = layer(x)\n",
        "    x = self.final_layer(x)\n",
        "    return self.max_flow(x), self.min_flow(x)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QpHibrNGRwM"
      },
      "source": [
        "c = MetaDataEncoder(2, 128, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwgcwWdSKBwu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "729bfa33-9864-4f64-f944-52a41339ab09"
      },
      "source": [
        "dummy_data = torch.rand(1, 6)\n",
        "c(dummy_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.2160]], grad_fn=<AddmmBackward>),\n",
              " tensor([[-0.1116]], grad_fn=<AddmmBackward>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5yz25IhKip4"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "from typing import List\n",
        "import os\n",
        "import json\n",
        "class DataLoading(Dataset):\n",
        "  def __init__(self, data_directory: str, meta_keys:List[str], target_keys:List[str]):\n",
        "    self.file_list = sorted(os.listdir(data_directory))\n",
        "    self.dir_path = data_directory\n",
        "    self.key_list = meta_keys\n",
        "    self.target_keys = target_keys\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    file_name = self.file_list[idx]\n",
        "    file_path = os.path.join(self.dir_path, file_name)\n",
        "    source_data = []\n",
        "    targs = {}\n",
        "    with open(file_path) as f:\n",
        "      data = json.load(f)\n",
        "    for key, value in data.items():\n",
        "      if key in self.key_list:\n",
        "        source_data.append(value)\n",
        "      elif key in self.target_keys:\n",
        "        targs[key] = value\n",
        "    return torch.FloatTensor(source_data), targs\n",
        "\n",
        "\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7oYhyCnQepL"
      },
      "source": [
        "test_loader = DataLoading(\"meta2\", [\"nan_flow\", \"nan_precip\"], [\"max_flow\", \"min_flow\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMDOjU39QgA5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "299b3da0-668d-4a98-cdf2-7323d60f04c5"
      },
      "source": [
        "test_loader[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([12931.,   729.]), {'max_flow': 41300.0, 'min_flow': 91.3})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRhAcKg-R532",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "outputId": "870a990d-62ba-4985-e1cb-5c2a101b26cf"
      },
      "source": [
        "from torch import optim\n",
        "criterion = torch.nn.MSELoss()\n",
        "opt = optim.Adam(c.parameters(), lr=0.0001)\n",
        "for epoch in range(10):\n",
        "  i = 0\n",
        "  running_loss = 0.0\n",
        "  for src, trg in test_loader:\n",
        "    opt.zero_grad()\n",
        "    # TODO figure how to avoid\n",
        "    output = c(src)\n",
        "    min_loss = criterion(output[0], torch.as_tensor(trg[\"max_flow\"]))\n",
        "    max_loss = criterion(output[1], torch.as_tensor(trg[\"min_flow\"]))\n",
        "    min_loss.backward()\n",
        "    max_loss.backward()\n",
        "    opt.step()\n",
        "    running_loss += min_loss.item() + max_loss.item()\n",
        "    i+=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-ee605a450b71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmax_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"min_flow\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmin_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mmax_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmin_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmax_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY5h1PkAV3wv"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}