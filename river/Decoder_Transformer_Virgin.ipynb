{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Virg2n River Predict",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "80ad4d3982ec4e96805c2b0f7397b368": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a5ebf545e4e945a2b9094092d79bac3d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dda26a159c804c849fdceffa2c37d082",
              "IPY_MODEL_b71a60b7870a492f82bf0b30934d41db"
            ]
          }
        },
        "a5ebf545e4e945a2b9094092d79bac3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dda26a159c804c849fdceffa2c37d082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_a8b927bb93aa4719b9988eb08467dd56",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.34MB of 0.34MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_deeae526bda84d9aa1b97e1910e60436"
          }
        },
        "b71a60b7870a492f82bf0b30934d41db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9eb09ebfac934ec4a6c16e57ef7171e4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c0834f47d6f4846a8246f6957b34a84"
          }
        },
        "a8b927bb93aa4719b9988eb08467dd56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "deeae526bda84d9aa1b97e1910e60436": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9eb09ebfac934ec4a6c16e57ef7171e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c0834f47d6f4846a8246f6957b34a84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "71366379a50441a28ad937618678a08e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_be0087d7b1374520a48163e30d32b53e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3ca8ddd9a64349d0837ac29f5e001e1a",
              "IPY_MODEL_902d0986fafe4e539b611aef7dc4ae1c"
            ]
          }
        },
        "be0087d7b1374520a48163e30d32b53e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ca8ddd9a64349d0837ac29f5e001e1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_69653ad203d24cf0b8008275517b94e6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.34MB of 0.34MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dd1040e800664e67bec572f9662852be"
          }
        },
        "902d0986fafe4e539b611aef7dc4ae1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4588bf509fb14923a9a257171143528a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d78af0168cd5423d9a4c48e63a3246c8"
          }
        },
        "69653ad203d24cf0b8008275517b94e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dd1040e800664e67bec572f9662852be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4588bf509fb14923a9a257171143528a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d78af0168cd5423d9a4c48e63a3246c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d9c55afdff0849f09560f4d9d6622fcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fb70d8e0c72f4e1d8e85ef4fa4d99eb5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_076a3e4ab43f48c0b8a1786275a0fcfb",
              "IPY_MODEL_12098e8b05824b1c833c4a748875e65b"
            ]
          }
        },
        "fb70d8e0c72f4e1d8e85ef4fa4d99eb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "076a3e4ab43f48c0b8a1786275a0fcfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_1dd5f5eb07024db2867f9a04277999ad",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.31MB of 0.31MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_386360c2cf82471fbeef670ef1877476"
          }
        },
        "12098e8b05824b1c833c4a748875e65b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dd56d74497c34b5c94b7f7f482d1b70e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_98041049059e4d59811b7692745991bb"
          }
        },
        "1dd5f5eb07024db2867f9a04277999ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "386360c2cf82471fbeef670ef1877476": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dd56d74497c34b5c94b7f7f482d1b70e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "98041049059e4d59811b7692745991bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a642a04b7d0547e0944a2c199221e9de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_072fab3252124d4cb46446da2e7e1c65",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_82e7b64d929c4f2db73396d40b7f1f06",
              "IPY_MODEL_b45550a41bbc408893924711c10d4ccb"
            ]
          }
        },
        "072fab3252124d4cb46446da2e7e1c65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "82e7b64d929c4f2db73396d40b7f1f06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_1c579a4d019e42df948b3fed0b385ac6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.31MB of 0.31MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_28a33681617e4ab6a4583df65f536141"
          }
        },
        "b45550a41bbc408893924711c10d4ccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_56a38937d58548bda41ad31de5975e95",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b0fb0c59fef14c808691c54d2ac780da"
          }
        },
        "1c579a4d019e42df948b3fed0b385ac6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "28a33681617e4ab6a4583df65f536141": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "56a38937d58548bda41ad31de5975e95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b0fb0c59fef14c808691c54d2ac780da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "12c9f03fcd7144058d93cbd7d5347ba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bdd0c8f51e3f46bab051a84fae701be8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0511b91420e9480996043e5c45fa6915",
              "IPY_MODEL_4ae3f10111b24985975025b40090bc32"
            ]
          }
        },
        "bdd0c8f51e3f46bab051a84fae701be8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0511b91420e9480996043e5c45fa6915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_86530ed6d48143c987f49a60672fa4cc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.34MB of 0.34MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c0e92d227199493d8cd94d6b84c1e373"
          }
        },
        "4ae3f10111b24985975025b40090bc32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_da6a6f1e8e26460e83a8a37a4c9ac6af",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5590cf529fb647dba6e4c4f1c8e59426"
          }
        },
        "86530ed6d48143c987f49a60672fa4cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c0e92d227199493d8cd94d6b84c1e373": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "da6a6f1e8e26460e83a8a37a4c9ac6af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5590cf529fb647dba6e4c4f1c8e59426": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8d9fd44552b649848e0ce2baab608c80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_32ed9911c3da41d381adaa5af6882f13",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_94d013cf9c7d4274b63152fd25f0de53",
              "IPY_MODEL_43247603397f4ed6bc988d51bdb12558"
            ]
          }
        },
        "32ed9911c3da41d381adaa5af6882f13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "94d013cf9c7d4274b63152fd25f0de53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_edff46fa0f5546b4a9d11ba1ba9979ea",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.34MB of 0.34MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bf69367416e04830b300a2f77de4b27e"
          }
        },
        "43247603397f4ed6bc988d51bdb12558": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5ebb4b99c2d54bf6b87bb60690b03470",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1584b81989b746ccb1406886fc4bbe26"
          }
        },
        "edff46fa0f5546b4a9d11ba1ba9979ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bf69367416e04830b300a2f77de4b27e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ebb4b99c2d54bf6b87bb60690b03470": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1584b81989b746ccb1406886fc4bbe26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd5ba6beb7d4436da3102cc3500fd998": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c49c4c55dd9e441186cc1abdc09529f0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2ee6d6866b4e4d6593098b64b6c4b639",
              "IPY_MODEL_5db7b5b84619464f89bf33e2b8fe6bd8"
            ]
          }
        },
        "c49c4c55dd9e441186cc1abdc09529f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ee6d6866b4e4d6593098b64b6c4b639": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_e504f3616a0b47acaf4c2bfeb3b4e304",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.31MB of 0.31MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1588f99f3e1f441497d98b08eddbc605"
          }
        },
        "5db7b5b84619464f89bf33e2b8fe6bd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_870c68a61bdb408b8afdfdd7d4e0c612",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a613a37703294b6a9b1764ead5c583c9"
          }
        },
        "e504f3616a0b47acaf4c2bfeb3b4e304": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1588f99f3e1f441497d98b08eddbc605": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "870c68a61bdb408b8afdfdd7d4e0c612": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a613a37703294b6a9b1764ead5c583c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5273b720fc684a9b9086ac737fe56e82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_13e2008c8cbb47b8a9bcb30f864579fd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_365f811cdde14d989dc08c5d7bf34e3a",
              "IPY_MODEL_9d4e6427467d40649b1748b121b9051e"
            ]
          }
        },
        "13e2008c8cbb47b8a9bcb30f864579fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "365f811cdde14d989dc08c5d7bf34e3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_4e465dacebfa46d391b3cff95a90b011",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.31MB of 0.31MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ecfc8a8a5e3647ee996b80e8187b4162"
          }
        },
        "9d4e6427467d40649b1748b121b9051e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_20e0a327b5fb455890fefa4baff998f4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_14e92d4467e94effb397f1fb885336a8"
          }
        },
        "4e465dacebfa46d391b3cff95a90b011": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ecfc8a8a5e3647ee996b80e8187b4162": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "20e0a327b5fb455890fefa4baff998f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "14e92d4467e94effb397f1fb885336a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9424d5cac7184d28983f2819a5c004ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_08db68183ea14d7f93cde9db0b173921",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9af0523b929b454b95abe1b8a2785cc7",
              "IPY_MODEL_1c5847eb23a6437da5b7686e75bc1d7d"
            ]
          }
        },
        "08db68183ea14d7f93cde9db0b173921": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9af0523b929b454b95abe1b8a2785cc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_36126aeb5f874d448836243f7d0284a1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.33MB of 0.33MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c31afadae53746108e30f5a93fa22468"
          }
        },
        "1c5847eb23a6437da5b7686e75bc1d7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4480ca54381f40cd9f0eb273faf26f5b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_22f62c8b3031475a8c0beb43ecc67ed3"
          }
        },
        "36126aeb5f874d448836243f7d0284a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c31afadae53746108e30f5a93fa22468": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4480ca54381f40cd9f0eb273faf26f5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "22f62c8b3031475a8c0beb43ecc67ed3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_A01ZR2ByhE"
      },
      "source": [
        "# Virgin River Forecasting \n",
        "In this notebook we will forecast river flows on the Virgin River in Utah. This is important since the Virgin River runs through Zion National Park and flash floods can be dangerous to hikers. We will leverage several models in Flow Forecast to get the best results and figure out the forecast."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXA8CPub9ZEc",
        "outputId": "452093b9-7101-491f-e47f-5588a32065cd"
      },
      "source": [
        "from google.colab import auth\n",
        "from datetime import datetime\n",
        "import os\n",
        "auth.authenticate_user()\n",
        "!git clone https://github.com/AIStream-Peelout/flow-forecast.git\n",
        "!gsutil cp gs://predict_cfs/virgin_final1.csv virgin_final.csv \n",
        "!gsutil cp -r gs://predict_cfs/joined_final_3 .\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'flow-forecast'...\n",
            "remote: Enumerating objects: 13893, done.\u001b[K\n",
            "remote: Counting objects: 100% (750/750), done.\u001b[K\n",
            "remote: Compressing objects: 100% (297/297), done.\u001b[K\n",
            "remote: Total 13893 (delta 506), reused 678 (delta 452), pack-reused 13143\u001b[K\n",
            "Receiving objects: 100% (13893/13893), 4.06 MiB | 15.70 MiB/s, done.\n",
            "Resolving deltas: 100% (10057/10057), done.\n",
            "Copying gs://predict_cfs/virgin_final1.csv...\n",
            "/ [1 files][  9.2 MiB/  9.2 MiB]                                                \n",
            "Operation completed over 1 objects/9.2 MiB.                                      \n",
            "Copying gs://predict_cfs/joined_final_3/0101000040B_flow.csv...\n",
            "Copying gs://predict_cfs/joined_final_3/0101007040B_flow.csv...\n",
            "Copying gs://predict_cfs/joined_final_3/01010500FVE_flow.csv...\n",
            "Copying gs://predict_cfs/joined_final_3/0101100040B_flow.csv...\n",
            "- [4 files][ 98.5 MiB/ 98.5 MiB]                                                \n",
            "==> NOTE: You are performing a sequence of gsutil operations that may\n",
            "run significantly faster if you instead use gsutil -m cp ... Please\n",
            "see the -m section under \"gsutil help options\" for further information\n",
            "about when gsutil -m can be advantageous.\n",
            "\n",
            "Copying gs://predict_cfs/joined_final_3/01017290CAR_flow.csv...\n",
            "Copying gs://predict_cfs/joined_final_3/01017550PQI_flow.csv...\n",
            "Copying gs://predict_cfs/joined_final_3/01017960HUL_flow.csv...\n",
            "Copying gs://predict_cfs/joined_final_3/01018000HUL_flow.csv...\n",
            "Copying gs://predict_cfs/joined_final_3/01018009HUL_flow.csv...\n",
            "Copying gs://predict_cfs/joined_final_3/01037380RKD_flow.csv...\n",
            "Copying gs://predict_cfs/joined_final_3/01042500GNR_flow.csv...\n",
            "Copying gs://predict_cfs/joined_final_3/01099500LWM_flow.csv...\n",
            "Copying gs://predict_cfs/joined_final_3/01638500FDK_flow.csv...\n",
            "Copying gs://predict_cfs/joined_final_3/01646500DCA_flow.csv...\n",
            "Copying gs://predict_cfs/joined_final_3/06741510FNL_flow.csv...\n",
            "Copying gs://predict_cfs/joined_final_3/09405500AZC_flow.csv...\n",
            "Copying gs://predict_cfs/joined_final_3/09406000AZC_flow.csv...\n",
            "Copying gs://predict_cfs/joined_final_3/09408135DXZ_flow.csv...\n",
            "| [18 files][444.4 MiB/444.4 MiB]   39.2 MiB/s                                  \n",
            "Operation completed over 18 objects/444.4 MiB.                                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46PFRR2i3n0s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95bac5bc-8d84-4aaf-be3b-08f1395a3de9"
      },
      "source": [
        "import pandas as pd\n",
        "!gsutil cp gs://aistream-datasets/flowdb/09405500AZC_flow.csv .\n",
        "df = pd.read_csv(\"09405500AZC_flow.csv\")\n",
        "df = df.dropna(subset=[\"hour_updated\", \"cfs\", \"p01m\"])\n",
        "df.to_csv(\"/content/joined_final_3/09405500AZC_flow.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://aistream-datasets/flowdb/09405500AZC_flow.csv...\n",
            "/ [1 files][ 19.6 MiB/ 19.6 MiB]                                                \n",
            "Operation completed over 1 objects/19.6 MiB.                                     \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (2,4,7,8,9,18) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "id": "T_yK6m4q-3TC",
        "outputId": "56851ee9-aa23-40bc-f878-e1713cb912cb"
      },
      "source": [
        "df = pd.read_csv(\"09405500AZC_flow.csv\")\n",
        "df = df.dropna(subset=[\"hour_updated\", \"cfs\", \"p01m\"])\n",
        "df.sort_values(by=[\"hour_updated\"])[1000:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (2,4,7,8,9,18) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0_x</th>\n",
              "      <th>hour_updated</th>\n",
              "      <th>p01m</th>\n",
              "      <th>valid</th>\n",
              "      <th>tmpf</th>\n",
              "      <th>dwpf</th>\n",
              "      <th>ice_accretion_1hr</th>\n",
              "      <th>mslp</th>\n",
              "      <th>drct</th>\n",
              "      <th>Unnamed: 0_y</th>\n",
              "      <th>agency_cd</th>\n",
              "      <th>site_no</th>\n",
              "      <th>datetime</th>\n",
              "      <th>tz_cd</th>\n",
              "      <th>144196_00060</th>\n",
              "      <th>144196_00060_cd</th>\n",
              "      <th>144197_00065</th>\n",
              "      <th>144197_00065_cd</th>\n",
              "      <th>cfs</th>\n",
              "      <th>height</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1000</th>\n",
              "      <td>1005</td>\n",
              "      <td>1005.0</td>\n",
              "      <td>2014-04-11 16:00:00+00:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2014-04-11 15:15</td>\n",
              "      <td>59.06</td>\n",
              "      <td>15.26</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>0.00</td>\n",
              "      <td>493678.0</td>\n",
              "      <td>USGS</td>\n",
              "      <td>9405500.0</td>\n",
              "      <td>2014-04-11 16:00:00+00:00</td>\n",
              "      <td>MDT</td>\n",
              "      <td>52.7</td>\n",
              "      <td>A</td>\n",
              "      <td>0.31</td>\n",
              "      <td>A</td>\n",
              "      <td>52.7</td>\n",
              "      <td>0.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1001</th>\n",
              "      <td>1006</td>\n",
              "      <td>1006.0</td>\n",
              "      <td>2014-04-11 17:00:00+00:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2014-04-11 16:15</td>\n",
              "      <td>68.42</td>\n",
              "      <td>11.00</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>130.00</td>\n",
              "      <td>493682.0</td>\n",
              "      <td>USGS</td>\n",
              "      <td>9405500.0</td>\n",
              "      <td>2014-04-11 17:00:00+00:00</td>\n",
              "      <td>MDT</td>\n",
              "      <td>52.7</td>\n",
              "      <td>A</td>\n",
              "      <td>0.31</td>\n",
              "      <td>A</td>\n",
              "      <td>52.7</td>\n",
              "      <td>0.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1002</th>\n",
              "      <td>1007</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>2014-04-11 18:00:00+00:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2014-04-11 17:15</td>\n",
              "      <td>74.36</td>\n",
              "      <td>8.42</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>100.00</td>\n",
              "      <td>493686.0</td>\n",
              "      <td>USGS</td>\n",
              "      <td>9405500.0</td>\n",
              "      <td>2014-04-11 18:00:00+00:00</td>\n",
              "      <td>MDT</td>\n",
              "      <td>55.5</td>\n",
              "      <td>A</td>\n",
              "      <td>0.34</td>\n",
              "      <td>A</td>\n",
              "      <td>55.5</td>\n",
              "      <td>0.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1003</th>\n",
              "      <td>1008</td>\n",
              "      <td>1008.0</td>\n",
              "      <td>2014-04-11 19:00:00+00:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2014-04-11 18:15</td>\n",
              "      <td>77.18</td>\n",
              "      <td>8.84</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>150.00</td>\n",
              "      <td>493690.0</td>\n",
              "      <td>USGS</td>\n",
              "      <td>9405500.0</td>\n",
              "      <td>2014-04-11 19:00:00+00:00</td>\n",
              "      <td>MDT</td>\n",
              "      <td>55.5</td>\n",
              "      <td>A</td>\n",
              "      <td>0.34</td>\n",
              "      <td>A</td>\n",
              "      <td>55.5</td>\n",
              "      <td>0.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1004</th>\n",
              "      <td>1009</td>\n",
              "      <td>1009.0</td>\n",
              "      <td>2014-04-11 20:00:00+00:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2014-04-11 19:15</td>\n",
              "      <td>77.96</td>\n",
              "      <td>8.78</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>0.00</td>\n",
              "      <td>493694.0</td>\n",
              "      <td>USGS</td>\n",
              "      <td>9405500.0</td>\n",
              "      <td>2014-04-11 20:00:00+00:00</td>\n",
              "      <td>MDT</td>\n",
              "      <td>56.4</td>\n",
              "      <td>A</td>\n",
              "      <td>0.35</td>\n",
              "      <td>A</td>\n",
              "      <td>56.4</td>\n",
              "      <td>0.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58155</th>\n",
              "      <td>58160</td>\n",
              "      <td>58153.0</td>\n",
              "      <td>2020-12-01 20:00:00+00:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2020-12-01 19:15</td>\n",
              "      <td>51.80</td>\n",
              "      <td>14.60</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>310.00</td>\n",
              "      <td>726147.0</td>\n",
              "      <td>USGS</td>\n",
              "      <td>9405500.0</td>\n",
              "      <td>2020-12-01 20:00:00+00:00</td>\n",
              "      <td>MST</td>\n",
              "      <td>57.6</td>\n",
              "      <td>P</td>\n",
              "      <td>7.44</td>\n",
              "      <td>P</td>\n",
              "      <td>57.6</td>\n",
              "      <td>7.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58156</th>\n",
              "      <td>58161</td>\n",
              "      <td>58154.0</td>\n",
              "      <td>2020-12-01 21:00:00+00:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2020-12-01 20:15</td>\n",
              "      <td>53.60</td>\n",
              "      <td>14.60</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>260.00</td>\n",
              "      <td>726151.0</td>\n",
              "      <td>USGS</td>\n",
              "      <td>9405500.0</td>\n",
              "      <td>2020-12-01 21:00:00+00:00</td>\n",
              "      <td>MST</td>\n",
              "      <td>56.6</td>\n",
              "      <td>P</td>\n",
              "      <td>7.43</td>\n",
              "      <td>P</td>\n",
              "      <td>56.6</td>\n",
              "      <td>7.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58157</th>\n",
              "      <td>58162</td>\n",
              "      <td>58155.0</td>\n",
              "      <td>2020-12-01 22:00:00+00:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2020-12-01 21:15</td>\n",
              "      <td>53.60</td>\n",
              "      <td>14.60</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>300.00</td>\n",
              "      <td>726155.0</td>\n",
              "      <td>USGS</td>\n",
              "      <td>9405500.0</td>\n",
              "      <td>2020-12-01 22:00:00+00:00</td>\n",
              "      <td>MST</td>\n",
              "      <td>55.6</td>\n",
              "      <td>P</td>\n",
              "      <td>7.42</td>\n",
              "      <td>P</td>\n",
              "      <td>55.6</td>\n",
              "      <td>7.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58158</th>\n",
              "      <td>58163</td>\n",
              "      <td>58156.0</td>\n",
              "      <td>2020-12-01 23:00:00+00:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2020-12-01 22:15</td>\n",
              "      <td>53.00</td>\n",
              "      <td>14.00</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>300.00</td>\n",
              "      <td>726159.0</td>\n",
              "      <td>USGS</td>\n",
              "      <td>9405500.0</td>\n",
              "      <td>2020-12-01 23:00:00+00:00</td>\n",
              "      <td>MST</td>\n",
              "      <td>55.6</td>\n",
              "      <td>P</td>\n",
              "      <td>7.42</td>\n",
              "      <td>P</td>\n",
              "      <td>55.6</td>\n",
              "      <td>7.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58159</th>\n",
              "      <td>58164</td>\n",
              "      <td>58157.0</td>\n",
              "      <td>2020-12-02 00:00:00+00:00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2020-12-01 23:15</td>\n",
              "      <td>50.00</td>\n",
              "      <td>13.40</td>\n",
              "      <td>M</td>\n",
              "      <td>M</td>\n",
              "      <td>300.00</td>\n",
              "      <td>726163.0</td>\n",
              "      <td>USGS</td>\n",
              "      <td>9405500.0</td>\n",
              "      <td>2020-12-02 00:00:00+00:00</td>\n",
              "      <td>MST</td>\n",
              "      <td>55.6</td>\n",
              "      <td>P</td>\n",
              "      <td>7.42</td>\n",
              "      <td>P</td>\n",
              "      <td>55.6</td>\n",
              "      <td>7.42</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>57025 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  Unnamed: 0_x  ...   cfs  height\n",
              "1000         1005        1005.0  ...  52.7    0.31\n",
              "1001         1006        1006.0  ...  52.7    0.31\n",
              "1002         1007        1007.0  ...  55.5    0.34\n",
              "1003         1008        1008.0  ...  55.5    0.34\n",
              "1004         1009        1009.0  ...  56.4    0.35\n",
              "...           ...           ...  ...   ...     ...\n",
              "58155       58160       58153.0  ...  57.6    7.44\n",
              "58156       58161       58154.0  ...  56.6    7.43\n",
              "58157       58162       58155.0  ...  55.6    7.42\n",
              "58158       58163       58156.0  ...  55.6    7.42\n",
              "58159       58164       58157.0  ...  55.6    7.42\n",
              "\n",
              "[57025 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhwUr16y5kOU"
      },
      "source": [
        "df['p01m_rolling1']=df['p01m'].rolling(48, win_type='triang').mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZruApg598kCj",
        "outputId": "e4540f49-0107-4747-e9b5-1cbecbff7158"
      },
      "source": [
        "len(df[df['p01m_rolling1']>0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14637"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wnjqUHSABKB"
      },
      "source": [
        "df['time_idx'] = range(1, len(df) + 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCmwBYVlAYiZ"
      },
      "source": [
        "df.to_csv(\"09405500AZC_flow.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPx5U5I9_IMh"
      },
      "source": [
        "df.to_csv(\"9405500AZC_flow.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikT8JmucBtwK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8910c769-ba93-48f5-ddc0-54ffa4dbab5d"
      },
      "source": [
        "import os\n",
        "os.chdir('flow-forecast')\n",
        "!pip install pandas --upgrade --force\n",
        "!pip install -r  requirements.txt\n",
        "!python setup.py develop\n",
        "!mkdir data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pandas\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/51/48f3fc47c4e2144da2806dfb6629c4dd1fa3d5a143f9652b141e979a8ca9/pandas-1.2.4-cp37-cp37m-manylinux1_x86_64.whl (9.9MB)\n",
            "\u001b[K     |████████████████████████████████| 9.9MB 5.2MB/s \n",
            "\u001b[?25hCollecting pytz>=2017.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/94/784178ca5dd892a98f113cdd923372024dc04b8d40abe77ca76b5fb90ca6/pytz-2021.1-py2.py3-none-any.whl (510kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 35.4MB/s \n",
            "\u001b[?25hCollecting python-dateutil>=2.7.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl (227kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 35.4MB/s \n",
            "\u001b[?25hCollecting numpy>=1.16.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/42/560d269f604d3e186a57c21a363e77e199358d054884e61b73e405dd217c/numpy-1.20.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.3MB)\n",
            "\u001b[K     |████████████████████████████████| 15.3MB 202kB/s \n",
            "\u001b[?25hCollecting six>=1.5\n",
            "  Downloading https://files.pythonhosted.org/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.20.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement six~=1.15.0, but you'll have six 1.16.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 1.2.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.15.0, but you'll have six 1.16.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pytz, six, python-dateutil, numpy, pandas\n",
            "  Found existing installation: pytz 2018.9\n",
            "    Uninstalling pytz-2018.9:\n",
            "      Successfully uninstalled pytz-2018.9\n",
            "  Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Found existing installation: python-dateutil 2.8.1\n",
            "    Uninstalling python-dateutil-2.8.1:\n",
            "      Successfully uninstalled python-dateutil-2.8.1\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "Successfully installed numpy-1.20.3 pandas-1.2.4 python-dateutil-2.8.1 pytz-2021.1 six-1.16.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil",
                  "numpy",
                  "pandas",
                  "pytz",
                  "six"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting shap==0.39.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/f4/c5b95cddae15be80f8e58b25edceca105aa83c0b8c86a1edad24a6af80d3/shap-0.39.0.tar.gz (356kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 5.3MB/s \n",
            "\u001b[?25hCollecting scikit-learn>=0.23.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/eb/a48f25c967526b66d5f1fa7a984594f0bf0a5afafa94a8c4dbc317744620/scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3MB 1.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.2.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.8.1+cu101)\n",
            "Collecting tb-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/a2/6ca4c89580a0fc0d42f7ef47233c2d51163bbea21ed0d9623608b6b28b85/tb_nightly-2.6.0a20210512-py3-none-any.whl (5.9MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9MB 18.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (0.11.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (0.16.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (2.10.0)\n",
            "Collecting wandb==0.10.27\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/28/4aefc543967839bdb4e139831b82004279f1c435cede2a9557ccf8369875/wandb-0.10.27-py2.py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 34.5MB/s \n",
            "\u001b[?25hCollecting google-cloud\n",
            "  Downloading https://files.pythonhosted.org/packages/ba/b1/7c54d1950e7808df06642274e677dbcedba57f75307adf2e5ad8d39e5e0e/google_cloud-0.34.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.18.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (3.13)\n",
            "Collecting plotly~=4.14.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/f6/bd3c17c8003b6641df1228e80e1acac97ed8402635e46c2571f8e1ef63af/plotly-4.14.3-py2.py3-none-any.whl (13.2MB)\n",
            "\u001b[K     |████████████████████████████████| 13.2MB 29.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz~=2021.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (2021.1)\n",
            "Collecting setuptools~=56.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/15/5041473f5d142ee93bf1593deb8f932e27a078f6f04e2020cf44044f72c5/setuptools-56.2.0-py3-none-any.whl (785kB)\n",
            "\u001b[K     |████████████████████████████████| 788kB 28.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 16)) (1.20.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 17)) (2.23.0)\n",
            "Requirement already satisfied: torchvision>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 18)) (0.9.1+cu101)\n",
            "Collecting mpld3~=0.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/b4/f380b6d58658106870161d703972b74fc2e66317acf298f873c0816d1fb2/mpld3-0.5.2.tar.gz (888kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 28.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numba>=0.50 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (0.51.2)\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 21)) (1.8.5)\n",
            "Collecting sphinx-rtd-theme\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/24/2475e8f83519b54b2148d4a56eb1111f9cec630d088c3ffc214492c12107/sphinx_rtd_theme-0.5.2-py2.py3-none-any.whl (9.1MB)\n",
            "\u001b[K     |████████████████████████████████| 9.2MB 22.2MB/s \n",
            "\u001b[?25hCollecting sphinx-autodoc-typehints\n",
            "  Downloading https://files.pythonhosted.org/packages/25/04/f59887284d9ea7e5e1473b74177fc8fca43c949a683750c733a154ba8148/sphinx_autodoc_typehints-1.12.0-py3-none-any.whl\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from shap==0.39.0->-r requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap==0.39.0->-r requirements.txt (line 1)) (4.41.1)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/78/c2/b3f55dfdb8af9812fdb9baf70cacf3b9e82e505b2bd4324d588888b81202/slicer-0.0.7-py3-none-any.whl\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap==0.39.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23.0->-r requirements.txt (line 2)) (1.0.1)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 3)) (2.8.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r requirements.txt (line 4)) (3.7.4.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->-r requirements.txt (line 5)) (1.30.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->-r requirements.txt (line 5)) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->-r requirements.txt (line 5)) (0.4.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->-r requirements.txt (line 5)) (1.8.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->-r requirements.txt (line 5)) (1.32.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->-r requirements.txt (line 5)) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->-r requirements.txt (line 5)) (3.12.4)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/f9/802efd84988bffd9f644c03b6e66fde8e76c3aa33db4279ddd11c5d61f4b/tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9MB 31.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly->-r requirements.txt (line 5)) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tb-nightly->-r requirements.txt (line 5)) (0.36.2)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn->-r requirements.txt (line 6)) (3.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->-r requirements.txt (line 8)) (1.16.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.10.27->-r requirements.txt (line 9)) (2.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.10.27->-r requirements.txt (line 9)) (5.4.8)\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 10.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.10.27->-r requirements.txt (line 9)) (7.1.2)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Collecting pathtools\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 27.2MB/s \n",
            "\u001b[?25hCollecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/4a/a54b254f67d8f4052338d54ebe90126f200693440a93ef76d254d581e3ec/sentry_sdk-1.1.0-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 39.2MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: google-resumable-media<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage->-r requirements.txt (line 11)) (0.4.1)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage->-r requirements.txt (line 11)) (1.0.3)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly~=4.14.3->-r requirements.txt (line 13)) (1.3.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 17)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 17)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 17)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->-r requirements.txt (line 17)) (2020.12.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.6.0->-r requirements.txt (line 18)) (7.1.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from mpld3~=0.5->-r requirements.txt (line 19)) (2.11.3)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.50->-r requirements.txt (line 20)) (0.34.0)\n",
            "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.7/dist-packages (from sphinx->-r requirements.txt (line 21)) (0.17.1)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx->-r requirements.txt (line 21)) (2.6.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from sphinx->-r requirements.txt (line 21)) (20.9)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from sphinx->-r requirements.txt (line 21)) (1.2.4)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx->-r requirements.txt (line 21)) (0.7.12)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx->-r requirements.txt (line 21)) (2.1.0)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx->-r requirements.txt (line 21)) (2.9.1)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx->-r requirements.txt (line 21)) (1.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly->-r requirements.txt (line 5)) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly->-r requirements.txt (line 5)) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly->-r requirements.txt (line 5)) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly->-r requirements.txt (line 5)) (4.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn->-r requirements.txt (line 6)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn->-r requirements.txt (line 6)) (2.4.7)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->-r requirements.txt (line 11)) (1.26.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->mpld3~=0.5->-r requirements.txt (line 19)) (1.1.1)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->sphinx->-r requirements.txt (line 21)) (1.1.4)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tb-nightly->-r requirements.txt (line 5)) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly->-r requirements.txt (line 5)) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly->-r requirements.txt (line 5)) (3.1.0)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage->-r requirements.txt (line 11)) (1.53.0)\n",
            "Building wheels for collected packages: shap, mpld3, subprocess32, pathtools\n",
            "  Building wheel for shap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for shap: filename=shap-0.39.0-cp37-cp37m-linux_x86_64.whl size=491655 sha256=fd709d2e511c53dc6643f0f2bc6790e603f56889d5e558675ad4c01de3837829\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/27/f5/a8ab9da52fd159aae6477b5ede6eaaec69fd130fa0fa59f283\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.5.2-cp37-none-any.whl size=200617 sha256=fe89787e3727799da4c6e50e87f71d917dd6538bdc0b93d7434ff2237905416b\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/73/06/ea4b85609301850b1289a282852d92e22fcbf7a250ed5f547f\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6489 sha256=83af1fa729de0190d7619cd885d1fc9efa7f17b5e3ee72344ec5123a3c62bb33\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8786 sha256=85af4097de184357c6c0c4adead37f4dd1d41f185ee30557644b51cfaabd2173\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "Successfully built shap mpld3 subprocess32 pathtools\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 1.2.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.15.0, but you'll have six 1.16.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: sphinx-rtd-theme 0.5.2 has requirement docutils<0.17, but you'll have docutils 0.17.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: sphinx-autodoc-typehints 1.12.0 has requirement Sphinx>=3.0, but you'll have sphinx 1.8.5 which is incompatible.\u001b[0m\n",
            "Installing collected packages: threadpoolctl, scikit-learn, slicer, shap, setuptools, tensorboard-data-server, tb-nightly, subprocess32, configparser, pathtools, shortuuid, smmap, gitdb, GitPython, sentry-sdk, docker-pycreds, wandb, google-cloud, plotly, mpld3, sphinx-rtd-theme, sphinx-autodoc-typehints\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: setuptools 56.1.0\n",
            "    Uninstalling setuptools-56.1.0:\n",
            "      Successfully uninstalled setuptools-56.1.0\n",
            "  Found existing installation: plotly 4.4.1\n",
            "    Uninstalling plotly-4.4.1:\n",
            "      Successfully uninstalled plotly-4.4.1\n",
            "Successfully installed GitPython-3.1.14 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 google-cloud-0.34.0 mpld3-0.5.2 pathtools-0.1.2 plotly-4.14.3 scikit-learn-0.24.2 sentry-sdk-1.1.0 setuptools-56.2.0 shap-0.39.0 shortuuid-1.0.1 slicer-0.0.7 smmap-4.0.0 sphinx-autodoc-typehints-1.12.0 sphinx-rtd-theme-0.5.2 subprocess32-3.5.4 tb-nightly-2.6.0a20210512 tensorboard-data-server-0.6.1 threadpoolctl-2.1.0 wandb-0.10.27\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/setuptools/dist.py:469: UserWarning: Normalizing '0.956dev' to '0.956.dev0'\n",
            "  warnings.warn(tmpl.format(**locals()))\n",
            "running develop\n",
            "running egg_info\n",
            "creating flood_forecast.egg-info\n",
            "writing flood_forecast.egg-info/PKG-INFO\n",
            "writing dependency_links to flood_forecast.egg-info/dependency_links.txt\n",
            "writing requirements to flood_forecast.egg-info/requires.txt\n",
            "writing top-level names to flood_forecast.egg-info/top_level.txt\n",
            "writing manifest file 'flood_forecast.egg-info/SOURCES.txt'\n",
            "package init file 'flood_forecast/__init__.py' not found (or not a regular file)\n",
            "package init file 'flood_forecast/transformer_xl/__init__.py' not found (or not a regular file)\n",
            "package init file 'flood_forecast/preprocessing/__init__.py' not found (or not a regular file)\n",
            "package init file 'flood_forecast/da_rnn/__init__.py' not found (or not a regular file)\n",
            "package init file 'flood_forecast/basic/__init__.py' not found (or not a regular file)\n",
            "package init file 'flood_forecast/meta_models/__init__.py' not found (or not a regular file)\n",
            "package init file 'flood_forecast/gcp_integration/__init__.py' not found (or not a regular file)\n",
            "package init file 'flood_forecast/deployment/__init__.py' not found (or not a regular file)\n",
            "package init file 'flood_forecast/custom/__init__.py' not found (or not a regular file)\n",
            "adding license file 'LICENSE' (matched pattern 'LICEN[CS]E*')\n",
            "writing manifest file 'flood_forecast.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "Creating /usr/local/lib/python3.7/dist-packages/flood-forecast.egg-link (link to .)\n",
            "Adding flood-forecast 0.956.dev0 to easy-install.pth file\n",
            "\n",
            "Installed /content/flow-forecast\n",
            "Processing dependencies for flood-forecast==0.956.dev0\n",
            "error: Sphinx 1.8.5 is installed but Sphinx>=3.0 is required by {'sphinx-autodoc-typehints'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "As1lsyvyBxfb",
        "outputId": "7186a098-b85d-413e-80bd-19c7fd9c2720"
      },
      "source": [
        "!wandb login\n",
        "os.environ['MODEL_BUCKET'] = \"predict_cfs\"\n",
        "os.environ[\"ENVIRONMENT_GCP\"] = \"Colab\"\n",
        "os.environ[\"GCP_PROJECT\"] = \"gmap-997\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32crDt2qB7KC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "da502d1b-7114-41a8-ccba-32433ce8d2f7"
      },
      "source": [
        "\n",
        "import json\n",
        "import os\n",
        "import subprocess as subp\n",
        "from flood_forecast.trainer import train_function\n",
        "import traceback\n",
        "from flood_forecast.long_train import split_on_letter\n",
        "\n",
        "#!gsutil cp -r add_thing2 gs://predict_cfs/day_addition\n",
        "def loop_through(data_dir:str, interrmittent_gcs=False, use_transfer=True, start_index=0, end_index=25): \n",
        "  \"\"\"\n",
        "  Function that makes and executes a set of config files\n",
        "  This is since we have over 9k files.\n",
        "  \"\"\"\n",
        "  if not os.path.exists(\"model_save\"):\n",
        "    os.mkdir(\"model_save\")\n",
        "  sorted_dir_list = sorted(os.listdir(data_dir))\n",
        "  #total = len(sorted_dir_list)\n",
        "  previous_gage = \"\"\n",
        "  prev_config = {\"pretrained_rivers\":[]}\n",
        "  for i in range(start_index, end_index):\n",
        "      file_name = sorted_dir_list[i]\n",
        "      station_id_gage = file_name.split(\"_flow.csv\")[0]\n",
        "      res = split_on_letter(station_id_gage)\n",
        "      gage_id = res[0]\n",
        "      station_id = res[1]\n",
        "      file_path_name = os.path.join(data_dir, file_name)\n",
        "      correct_file = None\n",
        "      if use_transfer and len(os.listdir(\"model_save\")) >0:\n",
        "        print(\"Utilizing transfer learning\")\n",
        "        weight_files = filter(lambda x: x.endswith(\".pth\"), os.listdir(\"model_save\"))\n",
        "        paths = [] \n",
        "        for weight_file in weight_files:\n",
        "             paths.append(os.path.join(\"model_save\", weight_file)) \n",
        "        correct_file = max(paths, key = os.path.getctime)\n",
        "        prev_config[\"pretrained_rivers\"].append(previous_gage)\n",
        "      sweep_full = wandb.sweep(wandb_sweep_config_full, project=\"github_aistream-peelout_flow-forecast\")\n",
        "      #sweep_id = \"21i08e3p\"\n",
        "      wandb.agent(sweep_full, lambda:train_function(\"PyTorch\", make_config_file(file_path_name, gage_id, station_id, correct_file, prev_config[\"pretrained_rivers\"])))\n",
        "      full_config = make_config_file(file_path_name, gage_id, station_id, correct_file, prev_config[\"pretrained_rivers\"])\n",
        "      try: \n",
        "        #model = train_function(\"PyTorch\", config)\n",
        "        print(\"temp disable\")\n",
        "      except Exception as e:\n",
        "        print(\"An exception occured for: \" + file_name_json)\n",
        "        traceback.print_exc()\n",
        "        print(e)\n",
        "      previous_gage = gage_id\n",
        "\n",
        "def make_config_file(flow_file_path, gage_id, station_id, weight_path=None, pretrained=[]):\n",
        "  run = wandb.init(project=\"github_aistream-peelout_flow-forecast\")\n",
        "  wandb_config = run.config\n",
        "  the_wandb_c = run.config\n",
        "  print(wandb_config)\n",
        "  the_config4 =  {\"model_name\": \"DecoderTransformer\",\n",
        "    \"model_type\": \"PyTorch\",\n",
        "    \"model_params\": {\n",
        "        \"dropout\":wandb_config[\"dropout\"],\n",
        "        \"n_embd\": 128,\n",
        "        \"n_head\": wandb_config[\"n_heads\"],\n",
        "        \"q_len\": wandb_config[\"q_len\"],\n",
        "        \"forecast_history\":wandb_config[\"forecast_history\"],\n",
        "        \"n_time_series\":7,\n",
        "        \"forecast_length\":wandb_config[\"forecast_length\"],\n",
        "        \"num_layer\": wandb_config[\"number_encoder_layers\"],\n",
        "        \"additional_params\": {}\n",
        "    },\n",
        "    \"dataset_params\":\n",
        "    {  \"class\": \"default\",\n",
        "       \"scaled_cols\":[\"cfs\", \"tmpf\", \"dwpf\"],\n",
        "       \"num_workers\":2,\n",
        "       \"pin_memory\": True,\n",
        "       \"training_path\": flow_file_path,\n",
        "       \"validation_path\": flow_file_path,\n",
        "       \"test_path\": flow_file_path,\n",
        "       \"batch_size\":wandb_config[\"batch_size\"],\n",
        "       \"forecast_test_len\":100,\n",
        "       \"forecast_history\":wandb_config[\"forecast_history\"],\n",
        "       \"forecast_length\":wandb_config[\"forecast_length\"],\n",
        "       \"scaler\": \"StandardScaler\",\n",
        "       \"train_start\":1000,\n",
        "       \"train_end\": 50000,\n",
        "       \"valid_start\":50001,\n",
        "       \"valid_end\": 57000,\n",
        "       \"sort_column\": \"hour_updated\",\n",
        "       \"test_start\": 57000,\n",
        "       \"test_end\":58000,\n",
        "       \"target_col\": [\"cfs\"],\n",
        "       \"relevant_cols\": [\"cfs\", \"tmpf\", \"p01m\", \"dwpf\", \"p01m_rolling1\"], \n",
        "       \"interpolate\":{\n",
        "           \"method\":\"back_forward_generic\",\n",
        "           \"params\":{\n",
        "               \"relevant_columns\":[\"cfs\", \"tmpf\", \"p01m\", \"dwpf\", \"p01m_rolling1\"]\n",
        "           }\n",
        "\n",
        "       },\n",
        "     \"feature_param\":\n",
        "     {\n",
        "         \"datetime_params\":{\n",
        "            \"hour\":\"numerical\",\n",
        "            \"month\": \"numerical\"\n",
        "         }\n",
        "     }\n",
        "    },\n",
        "    \"training_params\":\n",
        "    {\n",
        "       \"criterion\":\"MSE\",\n",
        "       \"optimizer\": \"SGD\",\n",
        "       #\"criterion_params\":{\"baseline_method\":\"mean\"},\n",
        "    \"optim_params\":{\n",
        "       \"lr\": the_wandb_c[\"lr\"]\n",
        "    },\n",
        "       \"epochs\": 11,\n",
        "       \"batch_size\":wandb_config[\"batch_size\"]\n",
        "    },\n",
        "    \"early_stopping\":{\n",
        "        \"patience\":3\n",
        "    },\n",
        "    \"GCS\": True,\n",
        "    \"sweep\":True,\n",
        "    \"wandb\":False,\n",
        "    \"forward_params\":{},\n",
        "   \"metrics\":[\"MSE\", \"DilateLoss\"],\n",
        "   \"inference_params\":\n",
        "   {     \n",
        "         \"datetime_start\":\"2020-05-31\",\n",
        "          \"hours_to_forecast\":336, \n",
        "          \"num_prediction_samples\": 20,\n",
        "          \"test_csv_path\":flow_file_path,\n",
        "          \"decoder_params\":{\n",
        "            \"decoder_function\": \"simple_decode\", \n",
        "            \"unsqueeze_dim\": 1},\n",
        "          \"dataset_params\":{\n",
        "             \"scaled_cols\":[\"cfs\", \"tmpf\", \"dwpf\"],\n",
        "             \"file_path\": flow_file_path,\n",
        "             \"sort_column\": \"hour_updated\",\n",
        "             \"scaling\": \"StandardScaler\",\n",
        "             \"forecast_history\": wandb_config[\"forecast_history\"],\n",
        "             \"forecast_length\":wandb_config[\"forecast_length\"],\n",
        "             \"relevant_cols\": [\"cfs\", \"tmpf\", \"p01m\", \"dwpf\", \"p01m_rolling1\"],\n",
        "             \"target_col\": [\"cfs\"],\n",
        "             \"interpolate_param\":{\n",
        "                 \"method\":\"back_forward_generic\",\n",
        "                 \"params\":{\"relevant_columns\":[\"cfs\", \"tmpf\", \"p01m\", \"dwpf\", \"p01m_rolling1\"]}\n",
        "                 }, \n",
        "            \"feature_params\":\n",
        "        {\n",
        "         \"datetime_params\":{\n",
        "            \"hour\":\"numerical\",\n",
        "            \"month\": \"numerical\"\n",
        "         \n",
        "     }\n",
        "             }\n",
        "          }\n",
        "          } \n",
        "    }\n",
        "\n",
        "      \n",
        "  if weight_path:\n",
        "    the_config4[\"weight_path\"] = weight_path\n",
        "  wandb.config.update(the_config4)\n",
        "  print(\"config made\")\n",
        "  return the_config4\n",
        "  \n",
        "wandb_sweep_config_full = {\n",
        "  \"name\": \"Default sweep\",\n",
        "  \"method\": \"grid\",\n",
        "  \"parameters\": {\n",
        "        \"batch_size\": {\n",
        "            \"values\": [100, 250, 400]\n",
        "        },\n",
        "        \"lr\":{\n",
        "            \"values\":[0.001, 0.0001, 0.00001]\n",
        "        },\n",
        "        \"forecast_history\":{\n",
        "            \"values\":[ 24, 40, 100, 200]\n",
        "        },\n",
        "        \"forecast_length\":{\n",
        "            \"values\":[1, 5, 10, 20]\n",
        "        },\n",
        "        \"number_encoder_layers\":\n",
        "        {\n",
        "            \"values\":[1, 2]\n",
        "        }, \n",
        "        \"dropout\":\n",
        "        {\n",
        "            \"values\":[0.4, 0.7, 0.9]\n",
        "        },\n",
        "        \"q_len\":{\n",
        "            \"values\":[1, 2]\n",
        "        },\n",
        "        \"n_heads\":{\n",
        "            \"values\": [2, 4, 8]\n",
        "        }\n",
        "        \n",
        "}}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xe but this version of numpy is 0xd"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sna511oClo3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "81ed72c35e6e4c73a7291b008df137ed",
            "80ad4d3982ec4e96805c2b0f7397b368",
            "a5ebf545e4e945a2b9094092d79bac3d",
            "dda26a159c804c849fdceffa2c37d082",
            "b71a60b7870a492f82bf0b30934d41db",
            "a8b927bb93aa4719b9988eb08467dd56",
            "deeae526bda84d9aa1b97e1910e60436",
            "9eb09ebfac934ec4a6c16e57ef7171e4",
            "2c0834f47d6f4846a8246f6957b34a84",
            "71366379a50441a28ad937618678a08e",
            "be0087d7b1374520a48163e30d32b53e",
            "3ca8ddd9a64349d0837ac29f5e001e1a",
            "902d0986fafe4e539b611aef7dc4ae1c",
            "69653ad203d24cf0b8008275517b94e6",
            "dd1040e800664e67bec572f9662852be",
            "4588bf509fb14923a9a257171143528a",
            "d78af0168cd5423d9a4c48e63a3246c8",
            "d9c55afdff0849f09560f4d9d6622fcc",
            "fb70d8e0c72f4e1d8e85ef4fa4d99eb5",
            "076a3e4ab43f48c0b8a1786275a0fcfb",
            "12098e8b05824b1c833c4a748875e65b",
            "1dd5f5eb07024db2867f9a04277999ad",
            "386360c2cf82471fbeef670ef1877476",
            "dd56d74497c34b5c94b7f7f482d1b70e",
            "98041049059e4d59811b7692745991bb",
            "a642a04b7d0547e0944a2c199221e9de",
            "072fab3252124d4cb46446da2e7e1c65",
            "82e7b64d929c4f2db73396d40b7f1f06",
            "b45550a41bbc408893924711c10d4ccb",
            "1c579a4d019e42df948b3fed0b385ac6",
            "28a33681617e4ab6a4583df65f536141",
            "56a38937d58548bda41ad31de5975e95",
            "b0fb0c59fef14c808691c54d2ac780da",
            "12c9f03fcd7144058d93cbd7d5347ba0",
            "bdd0c8f51e3f46bab051a84fae701be8",
            "0511b91420e9480996043e5c45fa6915",
            "4ae3f10111b24985975025b40090bc32",
            "86530ed6d48143c987f49a60672fa4cc",
            "c0e92d227199493d8cd94d6b84c1e373",
            "da6a6f1e8e26460e83a8a37a4c9ac6af",
            "5590cf529fb647dba6e4c4f1c8e59426",
            "8d9fd44552b649848e0ce2baab608c80",
            "32ed9911c3da41d381adaa5af6882f13",
            "94d013cf9c7d4274b63152fd25f0de53",
            "43247603397f4ed6bc988d51bdb12558",
            "edff46fa0f5546b4a9d11ba1ba9979ea",
            "bf69367416e04830b300a2f77de4b27e",
            "5ebb4b99c2d54bf6b87bb60690b03470",
            "1584b81989b746ccb1406886fc4bbe26",
            "bd5ba6beb7d4436da3102cc3500fd998",
            "c49c4c55dd9e441186cc1abdc09529f0",
            "2ee6d6866b4e4d6593098b64b6c4b639",
            "5db7b5b84619464f89bf33e2b8fe6bd8",
            "e504f3616a0b47acaf4c2bfeb3b4e304",
            "1588f99f3e1f441497d98b08eddbc605",
            "870c68a61bdb408b8afdfdd7d4e0c612",
            "a613a37703294b6a9b1764ead5c583c9",
            "5273b720fc684a9b9086ac737fe56e82",
            "13e2008c8cbb47b8a9bcb30f864579fd",
            "365f811cdde14d989dc08c5d7bf34e3a",
            "9d4e6427467d40649b1748b121b9051e",
            "4e465dacebfa46d391b3cff95a90b011",
            "ecfc8a8a5e3647ee996b80e8187b4162",
            "20e0a327b5fb455890fefa4baff998f4",
            "14e92d4467e94effb397f1fb885336a8",
            "9424d5cac7184d28983f2819a5c004ba",
            "08db68183ea14d7f93cde9db0b173921",
            "9af0523b929b454b95abe1b8a2785cc7",
            "1c5847eb23a6437da5b7686e75bc1d7d",
            "36126aeb5f874d448836243f7d0284a1",
            "c31afadae53746108e30f5a93fa22468",
            "4480ca54381f40cd9f0eb273faf26f5b",
            "22f62c8b3031475a8c0beb43ecc67ed3"
          ]
        },
        "outputId": "450e62eb-55bb-4d74-dba9-923a38f15cf6"
      },
      "source": [
        "import wandb\n",
        "sweep_full = wandb.sweep(wandb_sweep_config_full, project=\"github_aistream-peelout_flow-forecast\")\n",
        "sweepid = \"nq46n2lg\"\n",
        "wandb.agent(sweepid, lambda:train_function(\"PyTorch\", make_config_file(\"/content/09405500AZC_flow.csv\", \"virgin_river_09405500AZC\", \"AZC\")))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Create sweep with ID: oy0u1hi6\n",
            "Sweep URL: https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/sweeps/oy0u1hi6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 67k45oot with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tforecast_history: 24\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tforecast_length: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_heads: 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumber_encoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tq_len: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 9787<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.30 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81ed72c35e6e4c73a7291b008df137ed",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.27<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">distinctive-sweep-582</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/sweeps/nq46n2lg\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/sweeps/nq46n2lg</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/67k45oot\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/67k45oot</a><br/>\n",
              "                Run data is saved locally in <code>/content/flow-forecast/wandb/run-20210513_022304-67k45oot</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 100, 'dropout': 0.7, 'forecast_history': 24, 'forecast_length': 1, 'lr': 0.001, 'n_heads': 4, 'number_encoder_layers': 1, 'q_len': 2}\n",
            "config made\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "interpolate should be below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/flow-forecast/wandb/run-20210513_022059-g4mihgkj/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/flow-forecast/wandb/run-20210513_022059-g4mihgkj/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>3</td></tr><tr><td>_runtime</td><td>126</td></tr><tr><td>_timestamp</td><td>1620872585</td></tr><tr><td>_step</td><td>8</td></tr><tr><td>loss</td><td>0.32</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>▁▁▃▃▆▆██</td></tr><tr><td>_runtime</td><td>▁▁▃▃▅▅▇▇█</td></tr><tr><td>_timestamp</td><td>▁▁▃▃▅▅▇▇█</td></tr><tr><td>_step</td><td>▁▂▃▄▅▅▆▇█</td></tr><tr><td>loss</td><td>█▃▂▁</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">gallant-sweep-581</strong>: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/g4mihgkj\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/g4mihgkj</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 67k45oot errored: ValueError('You must call `wandb.init` before calling watch')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "Using Wandb config:\n",
            "<wandb.sdk.lib.preinit.PreInitObject object at 0x7f54b8162d90>\n",
            "Torch is using cuda\n",
            "using 2\n",
            "Pin memory set to true\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jy3iu02c with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tforecast_history: 24\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tforecast_length: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_heads: 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumber_encoder_layers: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tq_len: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.30 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.27<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">ethereal-sweep-583</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/sweeps/nq46n2lg\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/sweeps/nq46n2lg</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/jy3iu02c\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/jy3iu02c</a><br/>\n",
              "                Run data is saved locally in <code>/content/flow-forecast/wandb/run-20210513_022311-jy3iu02c</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 100, 'dropout': 0.7, 'forecast_history': 24, 'forecast_length': 1, 'lr': 0.001, 'n_heads': 4, 'number_encoder_layers': 2, 'q_len': 1}\n",
            "config made\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "Using Wandb config:\n",
            "{'batch_size': 100, 'dropout': 0.7, 'forecast_history': 24, 'forecast_length': 1, 'lr': 0.001, 'n_heads': 4, 'number_encoder_layers': 2, 'q_len': 1, 'model_name': 'DecoderTransformer', 'model_type': 'PyTorch', 'model_params': {'dropout': 0.7, 'n_embd': 128, 'n_head': 4, 'q_len': 1, 'forecast_history': 24, 'n_time_series': 7, 'forecast_length': 1, 'num_layer': 2, 'additional_params': {}}, 'dataset_params': {'class': 'default', 'scaled_cols': ['cfs', 'tmpf', 'dwpf'], 'num_workers': 2, 'pin_memory': True, 'training_path': '/content/09405500AZC_flow.csv', 'validation_path': '/content/09405500AZC_flow.csv', 'test_path': '/content/09405500AZC_flow.csv', 'batch_size': 100, 'forecast_test_len': 100, 'forecast_history': 24, 'forecast_length': 1, 'scaler': 'StandardScaler', 'train_start': 1000, 'train_end': 50000, 'valid_start': 50001, 'valid_end': 57000, 'sort_column': 'hour_updated', 'test_start': 57000, 'test_end': 58000, 'target_col': ['cfs'], 'relevant_cols': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1'], 'interpolate': {'method': 'back_forward_generic', 'params': {'relevant_columns': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1']}}, 'feature_param': {'datetime_params': {'hour': 'numerical', 'month': 'numerical'}}}, 'training_params': {'criterion': 'MSE', 'optimizer': 'SGD', 'optim_params': {'lr': 0.001}, 'epochs': 11, 'batch_size': 100}, 'early_stopping': {'patience': 3}, 'GCS': True, 'sweep': True, 'wandb': False, 'forward_params': {}, 'metrics': ['MSE', 'DilateLoss'], 'inference_params': {'datetime_start': '2020-05-31', 'hours_to_forecast': 336, 'num_prediction_samples': 20, 'test_csv_path': '/content/09405500AZC_flow.csv', 'decoder_params': {'decoder_function': 'simple_decode', 'unsqueeze_dim': 1}, 'dataset_params': {'scaled_cols': ['cfs', 'tmpf', 'dwpf'], 'file_path': '/content/09405500AZC_flow.csv', 'sort_column': 'hour_updated', 'scaling': 'StandardScaler', 'forecast_history': 24, 'forecast_length': 1, 'relevant_cols': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1'], 'target_col': ['cfs'], 'interpolate_param': {'method': 'back_forward_generic', 'params': {'relevant_columns': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1']}}, 'feature_params': {'datetime_params': {'hour': 'numerical', 'month': 'numerical'}}}}}\n",
            "Torch is using cuda\n",
            "using 2\n",
            "Pin memory set to true\n",
            "running torch_single_train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/transformer_xl/transformer_bottleneck.py:261: UserWarning:\n",
            "\n",
            "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:770: UserWarning:\n",
            "\n",
            "Using non-full backward hooks on a Module that does not take as input a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:795: UserWarning:\n",
            "\n",
            "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The running loss is: \n",
            "402.2163309485768\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 0\n",
            "0.8208496549970955\n",
            "Computing validation loss\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/custom/dilate_loss.py:44: UserWarning:\n",
            "\n",
            "torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running torch_single_train\n",
            "The running loss is: \n",
            "259.7934876496438\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 1\n",
            "0.5301907911217221\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "208.52743114501936\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 2\n",
            "0.4255661860102436\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "182.23571729136165\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 3\n",
            "0.37190962712522785\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "165.33609061030438\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 4\n",
            "0.33742059308225386\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "152.7038961602375\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 5\n",
            "0.31164060440864794\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "142.87846721633105\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 6\n",
            "0.2915887086047572\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "134.43257518380415\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 7\n",
            "0.27435219425266155\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "127.21401272743242\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 8\n",
            "0.2596204341376172\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "120.87139541952638\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 9\n",
            "0.24667631718270688\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "115.20905321184546\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 10\n",
            "0.23512051675886828\n",
            "Computing validation loss\n",
            "Computing validation loss\n",
            "test loss: 805.7209569327533\n",
            "Data saved to: \n",
            "13_May_202102_34AM.json\n",
            "Data saved to: \n",
            "13_May_202102_34AM_model.pth\n",
            "This model is currently forecasting for : 1 targets\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "CSV Path below\n",
            "/content/09405500AZC_flow.csv\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/transformer_xl/transformer_bottleneck.py:261: UserWarning:\n",
            "\n",
            "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "<class 'numpy.ndarray'>\n",
            "transform end tens preform\n",
            "Un-transforming data\n",
            "Current historical dataframe \n",
            "       Unnamed: 0  Unnamed: 0.1  Unnamed: 0_x  ... month       preds    pred_cfs\n",
            "53563       53697         53702       53696.0  ...     5    0.000000    0.000000\n",
            "53564       53698         53703       53697.0  ...     5    0.000000    0.000000\n",
            "53565       53699         53704       53698.0  ...     5    0.000000    0.000000\n",
            "53566       53700         53705       53699.0  ...     5    0.000000    0.000000\n",
            "53567       53701         53706       53700.0  ...     5    0.000000    0.000000\n",
            "...           ...           ...           ...  ...   ...         ...         ...\n",
            "53918       54052         54057       54051.0  ...     6  218.439041  218.439041\n",
            "53919       54053         54058       54052.0  ...     6  217.454758  217.454758\n",
            "53920       54054         54059       54053.0  ...     6  209.654419  209.654419\n",
            "53921       54055         54060       54054.0  ...     6  201.295975  201.295975\n",
            "53922       54056         54061       54055.0  ...     6  190.680481  190.680481\n",
            "\n",
            "[360 rows x 29 columns]\n",
            "begin fixed loss func\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/custom/dilate_loss.py:44: UserWarning:\n",
            "\n",
            "torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "\n",
            "/content/flow-forecast/flood_forecast/transformer_xl/transformer_bottleneck.py:261: UserWarning:\n",
            "\n",
            "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:795: UserWarning:\n",
            "\n",
            "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "plotting with CI now\n",
            "Now plotting final plots\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 9944<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80ad4d3982ec4e96805c2b0f7397b368",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.26MB of 0.26MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/flow-forecast/wandb/run-20210513_022311-jy3iu02c/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/flow-forecast/wandb/run-20210513_022311-jy3iu02c/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>10</td></tr><tr><td>_runtime</td><td>727</td></tr><tr><td>_timestamp</td><td>1620873318</td></tr><tr><td>_step</td><td>55</td></tr><tr><td>loss</td><td>0.23512</td></tr><tr><td>average_prediction_sharpe0</td><td>0.00115</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▄▄▅▅▅▅▆▆▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄████████████████████████</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄████████████████████████</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▅▃▃▂▂▂▁▁▁▁</td></tr><tr><td>average_prediction_sharpe0</td><td>▁</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 26 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">ethereal-sweep-583</strong>: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/jy3iu02c\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/jy3iu02c</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: u2bo1jfq with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tforecast_history: 24\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tforecast_length: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_heads: 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumber_encoder_layers: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tq_len: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.30 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.27<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">genial-sweep-584</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/sweeps/nq46n2lg\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/sweeps/nq46n2lg</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/u2bo1jfq\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/u2bo1jfq</a><br/>\n",
              "                Run data is saved locally in <code>/content/flow-forecast/wandb/run-20210513_023523-u2bo1jfq</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 100, 'dropout': 0.7, 'forecast_history': 24, 'forecast_length': 1, 'lr': 0.001, 'n_heads': 4, 'number_encoder_layers': 2, 'q_len': 2}\n",
            "config made\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "Using Wandb config:\n",
            "{'batch_size': 100, 'dropout': 0.7, 'forecast_history': 24, 'forecast_length': 1, 'lr': 0.001, 'n_heads': 4, 'number_encoder_layers': 2, 'q_len': 2, 'model_name': 'DecoderTransformer', 'model_type': 'PyTorch', 'model_params': {'dropout': 0.7, 'n_embd': 128, 'n_head': 4, 'q_len': 2, 'forecast_history': 24, 'n_time_series': 7, 'forecast_length': 1, 'num_layer': 2, 'additional_params': {}}, 'dataset_params': {'class': 'default', 'scaled_cols': ['cfs', 'tmpf', 'dwpf'], 'num_workers': 2, 'pin_memory': True, 'training_path': '/content/09405500AZC_flow.csv', 'validation_path': '/content/09405500AZC_flow.csv', 'test_path': '/content/09405500AZC_flow.csv', 'batch_size': 100, 'forecast_test_len': 100, 'forecast_history': 24, 'forecast_length': 1, 'scaler': 'StandardScaler', 'train_start': 1000, 'train_end': 50000, 'valid_start': 50001, 'valid_end': 57000, 'sort_column': 'hour_updated', 'test_start': 57000, 'test_end': 58000, 'target_col': ['cfs'], 'relevant_cols': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1'], 'interpolate': {'method': 'back_forward_generic', 'params': {'relevant_columns': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1']}}, 'feature_param': {'datetime_params': {'hour': 'numerical', 'month': 'numerical'}}}, 'training_params': {'criterion': 'MSE', 'optimizer': 'SGD', 'optim_params': {'lr': 0.001}, 'epochs': 11, 'batch_size': 100}, 'early_stopping': {'patience': 3}, 'GCS': True, 'sweep': True, 'wandb': False, 'forward_params': {}, 'metrics': ['MSE', 'DilateLoss'], 'inference_params': {'datetime_start': '2020-05-31', 'hours_to_forecast': 336, 'num_prediction_samples': 20, 'test_csv_path': '/content/09405500AZC_flow.csv', 'decoder_params': {'decoder_function': 'simple_decode', 'unsqueeze_dim': 1}, 'dataset_params': {'scaled_cols': ['cfs', 'tmpf', 'dwpf'], 'file_path': '/content/09405500AZC_flow.csv', 'sort_column': 'hour_updated', 'scaling': 'StandardScaler', 'forecast_history': 24, 'forecast_length': 1, 'relevant_cols': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1'], 'target_col': ['cfs'], 'interpolate_param': {'method': 'back_forward_generic', 'params': {'relevant_columns': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1']}}, 'feature_params': {'datetime_params': {'hour': 'numerical', 'month': 'numerical'}}}}}\n",
            "Torch is using cuda\n",
            "using 2\n",
            "Pin memory set to true\n",
            "running torch_single_train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/transformer_xl/transformer_bottleneck.py:261: UserWarning:\n",
            "\n",
            "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:770: UserWarning:\n",
            "\n",
            "Using non-full backward hooks on a Module that does not take as input a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:795: UserWarning:\n",
            "\n",
            "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The running loss is: \n",
            "333.40355226013344\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 0\n",
            "0.6804154127757825\n",
            "Computing validation loss\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/custom/dilate_loss.py:44: UserWarning:\n",
            "\n",
            "torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running torch_single_train\n",
            "The running loss is: \n",
            "230.4138611141243\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 1\n",
            "0.47023236962066184\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "192.03980585071258\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 2\n",
            "0.39191797112390325\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "170.43447127996478\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 3\n",
            "0.34782545159176487\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "155.3829979862785\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 4\n",
            "0.3171081591556704\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "145.0518752784701\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 5\n",
            "0.2960242352621839\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "136.54768053954467\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 6\n",
            "0.27866873579498913\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "129.46225500054425\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 7\n",
            "0.2642086836745801\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "123.52653794392245\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 8\n",
            "0.2520949753957601\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "118.00341620494146\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 9\n",
            "0.24082329837743155\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "113.28942021398689\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 10\n",
            "0.23120289839589162\n",
            "Computing validation loss\n",
            "Computing validation loss\n",
            "test loss: 832.6637946069241\n",
            "Data saved to: \n",
            "13_May_202102_46AM.json\n",
            "Data saved to: \n",
            "13_May_202102_46AM_model.pth\n",
            "This model is currently forecasting for : 1 targets\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "CSV Path below\n",
            "/content/09405500AZC_flow.csv\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/transformer_xl/transformer_bottleneck.py:261: UserWarning:\n",
            "\n",
            "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "<class 'numpy.ndarray'>\n",
            "transform end tens preform\n",
            "Un-transforming data\n",
            "Current historical dataframe \n",
            "       Unnamed: 0  Unnamed: 0.1  Unnamed: 0_x  ... month       preds    pred_cfs\n",
            "53563       53697         53702       53696.0  ...     5    0.000000    0.000000\n",
            "53564       53698         53703       53697.0  ...     5    0.000000    0.000000\n",
            "53565       53699         53704       53698.0  ...     5    0.000000    0.000000\n",
            "53566       53700         53705       53699.0  ...     5    0.000000    0.000000\n",
            "53567       53701         53706       53700.0  ...     5    0.000000    0.000000\n",
            "...           ...           ...           ...  ...   ...         ...         ...\n",
            "53918       54052         54057       54051.0  ...     6  120.042168  120.042168\n",
            "53919       54053         54058       54052.0  ...     6  119.078629  119.078629\n",
            "53920       54054         54059       54053.0  ...     6  118.804924  118.804924\n",
            "53921       54055         54060       54054.0  ...     6  119.134842  119.134842\n",
            "53922       54056         54061       54055.0  ...     6  120.012825  120.012825\n",
            "\n",
            "[360 rows x 29 columns]\n",
            "begin fixed loss func\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/custom/dilate_loss.py:44: UserWarning:\n",
            "\n",
            "torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "\n",
            "/content/flow-forecast/flood_forecast/transformer_xl/transformer_bottleneck.py:261: UserWarning:\n",
            "\n",
            "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:795: UserWarning:\n",
            "\n",
            "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "plotting with CI now\n",
            "Now plotting final plots\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 10243<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "71366379a50441a28ad937618678a08e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.26MB of 0.26MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/flow-forecast/wandb/run-20210513_023523-u2bo1jfq/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/flow-forecast/wandb/run-20210513_023523-u2bo1jfq/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>10</td></tr><tr><td>_runtime</td><td>721</td></tr><tr><td>_timestamp</td><td>1620874044</td></tr><tr><td>_step</td><td>55</td></tr><tr><td>loss</td><td>0.2312</td></tr><tr><td>average_prediction_sharpe0</td><td>0.00203</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▄▄▅▅▅▅▆▆▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄████████████████████████</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄████████████████████████</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▅▄▃▂▂▂▂▁▁▁</td></tr><tr><td>average_prediction_sharpe0</td><td>▁</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 26 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">genial-sweep-584</strong>: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/u2bo1jfq\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/u2bo1jfq</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ldmg6h0j with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tforecast_history: 24\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tforecast_length: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_heads: 8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumber_encoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tq_len: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.30 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.27<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">wandering-sweep-585</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/sweeps/nq46n2lg\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/sweeps/nq46n2lg</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/ldmg6h0j\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/ldmg6h0j</a><br/>\n",
              "                Run data is saved locally in <code>/content/flow-forecast/wandb/run-20210513_024729-ldmg6h0j</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 100, 'dropout': 0.7, 'forecast_history': 24, 'forecast_length': 1, 'lr': 0.001, 'n_heads': 8, 'number_encoder_layers': 1, 'q_len': 1}\n",
            "config made\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "Using Wandb config:\n",
            "{'batch_size': 100, 'dropout': 0.7, 'forecast_history': 24, 'forecast_length': 1, 'lr': 0.001, 'n_heads': 8, 'number_encoder_layers': 1, 'q_len': 1, 'model_name': 'DecoderTransformer', 'model_type': 'PyTorch', 'model_params': {'dropout': 0.7, 'n_embd': 128, 'n_head': 8, 'q_len': 1, 'forecast_history': 24, 'n_time_series': 7, 'forecast_length': 1, 'num_layer': 1, 'additional_params': {}}, 'dataset_params': {'class': 'default', 'scaled_cols': ['cfs', 'tmpf', 'dwpf'], 'num_workers': 2, 'pin_memory': True, 'training_path': '/content/09405500AZC_flow.csv', 'validation_path': '/content/09405500AZC_flow.csv', 'test_path': '/content/09405500AZC_flow.csv', 'batch_size': 100, 'forecast_test_len': 100, 'forecast_history': 24, 'forecast_length': 1, 'scaler': 'StandardScaler', 'train_start': 1000, 'train_end': 50000, 'valid_start': 50001, 'valid_end': 57000, 'sort_column': 'hour_updated', 'test_start': 57000, 'test_end': 58000, 'target_col': ['cfs'], 'relevant_cols': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1'], 'interpolate': {'method': 'back_forward_generic', 'params': {'relevant_columns': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1']}}, 'feature_param': {'datetime_params': {'hour': 'numerical', 'month': 'numerical'}}}, 'training_params': {'criterion': 'MSE', 'optimizer': 'SGD', 'optim_params': {'lr': 0.001}, 'epochs': 11, 'batch_size': 100}, 'early_stopping': {'patience': 3}, 'GCS': True, 'sweep': True, 'wandb': False, 'forward_params': {}, 'metrics': ['MSE', 'DilateLoss'], 'inference_params': {'datetime_start': '2020-05-31', 'hours_to_forecast': 336, 'num_prediction_samples': 20, 'test_csv_path': '/content/09405500AZC_flow.csv', 'decoder_params': {'decoder_function': 'simple_decode', 'unsqueeze_dim': 1}, 'dataset_params': {'scaled_cols': ['cfs', 'tmpf', 'dwpf'], 'file_path': '/content/09405500AZC_flow.csv', 'sort_column': 'hour_updated', 'scaling': 'StandardScaler', 'forecast_history': 24, 'forecast_length': 1, 'relevant_cols': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1'], 'target_col': ['cfs'], 'interpolate_param': {'method': 'back_forward_generic', 'params': {'relevant_columns': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1']}}, 'feature_params': {'datetime_params': {'hour': 'numerical', 'month': 'numerical'}}}}}\n",
            "Torch is using cuda\n",
            "using 2\n",
            "Pin memory set to true\n",
            "running torch_single_train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/transformer_xl/transformer_bottleneck.py:261: UserWarning:\n",
            "\n",
            "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:770: UserWarning:\n",
            "\n",
            "Using non-full backward hooks on a Module that does not take as input a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:795: UserWarning:\n",
            "\n",
            "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The running loss is: \n",
            "313.21973247808637\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 0\n",
            "0.6392239438328293\n",
            "Computing validation loss\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/custom/dilate_loss.py:44: UserWarning:\n",
            "\n",
            "torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running torch_single_train\n",
            "The running loss is: \n",
            "196.68310521519743\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 1\n",
            "0.4013940922759131\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "163.5052101960173\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 2\n",
            "0.3336841024408516\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "147.8973773996113\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 3\n",
            "0.3018313824481863\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "137.57767227632576\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 4\n",
            "0.28077075974760357\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "130.38827227652655\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 5\n",
            "0.2660985148500542\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "124.46029538993025\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 6\n",
            "0.25400060283659237\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "119.65812529082177\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 7\n",
            "0.24420025569555465\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "115.57815787312575\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 8\n",
            "0.23587379157780763\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "111.52217827166896\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 9\n",
            "0.22759628218707953\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "108.26803339153412\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 10\n",
            "0.22095517018680433\n",
            "Computing validation loss\n",
            "Computing validation loss\n",
            "test loss: 828.9704472757876\n",
            "Data saved to: \n",
            "13_May_202102_56AM.json\n",
            "Data saved to: \n",
            "13_May_202102_56AM_model.pth\n",
            "This model is currently forecasting for : 1 targets\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "CSV Path below\n",
            "/content/09405500AZC_flow.csv\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/transformer_xl/transformer_bottleneck.py:261: UserWarning:\n",
            "\n",
            "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "<class 'numpy.ndarray'>\n",
            "transform end tens preform\n",
            "Un-transforming data\n",
            "Current historical dataframe \n",
            "       Unnamed: 0  Unnamed: 0.1  Unnamed: 0_x  ... month       preds    pred_cfs\n",
            "53563       53697         53702       53696.0  ...     5    0.000000    0.000000\n",
            "53564       53698         53703       53697.0  ...     5    0.000000    0.000000\n",
            "53565       53699         53704       53698.0  ...     5    0.000000    0.000000\n",
            "53566       53700         53705       53699.0  ...     5    0.000000    0.000000\n",
            "53567       53701         53706       53700.0  ...     5    0.000000    0.000000\n",
            "...           ...           ...           ...  ...   ...         ...         ...\n",
            "53918       54052         54057       54051.0  ...     6  146.448257  146.448257\n",
            "53919       54053         54058       54052.0  ...     6  147.105804  147.105804\n",
            "53920       54054         54059       54053.0  ...     6  144.510696  144.510696\n",
            "53921       54055         54060       54054.0  ...     6  144.194962  144.194962\n",
            "53922       54056         54061       54055.0  ...     6  141.434723  141.434723\n",
            "\n",
            "[360 rows x 29 columns]\n",
            "begin fixed loss func\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/custom/dilate_loss.py:44: UserWarning:\n",
            "\n",
            "torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "\n",
            "/content/flow-forecast/flood_forecast/transformer_xl/transformer_bottleneck.py:261: UserWarning:\n",
            "\n",
            "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:795: UserWarning:\n",
            "\n",
            "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "plotting with CI now\n",
            "Now plotting final plots\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 10532<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d9c55afdff0849f09560f4d9d6622fcc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.26MB of 0.26MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/flow-forecast/wandb/run-20210513_024729-ldmg6h0j/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/flow-forecast/wandb/run-20210513_024729-ldmg6h0j/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>10</td></tr><tr><td>_runtime</td><td>541</td></tr><tr><td>_timestamp</td><td>1620874590</td></tr><tr><td>_step</td><td>55</td></tr><tr><td>loss</td><td>0.22096</td></tr><tr><td>average_prediction_sharpe0</td><td>0.00211</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▄▄▅▅▅▅▆▆▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▃▃▄▄▄▄▄▅████████████████████████</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▃▃▄▄▄▄▄▅████████████████████████</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▄▃▂▂▂▂▁▁▁▁</td></tr><tr><td>average_prediction_sharpe0</td><td>▁</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 26 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">wandering-sweep-585</strong>: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/ldmg6h0j\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/ldmg6h0j</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 41f487vc with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tforecast_history: 24\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tforecast_length: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_heads: 8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumber_encoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tq_len: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.30 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.27<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">legendary-sweep-586</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/sweeps/nq46n2lg\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/sweeps/nq46n2lg</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/41f487vc\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/41f487vc</a><br/>\n",
              "                Run data is saved locally in <code>/content/flow-forecast/wandb/run-20210513_025635-41f487vc</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 100, 'dropout': 0.7, 'forecast_history': 24, 'forecast_length': 1, 'lr': 0.001, 'n_heads': 8, 'number_encoder_layers': 1, 'q_len': 2}\n",
            "config made\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "Using Wandb config:\n",
            "{'batch_size': 100, 'dropout': 0.7, 'forecast_history': 24, 'forecast_length': 1, 'lr': 0.001, 'n_heads': 8, 'number_encoder_layers': 1, 'q_len': 2, 'model_name': 'DecoderTransformer', 'model_type': 'PyTorch', 'model_params': {'dropout': 0.7, 'n_embd': 128, 'n_head': 8, 'q_len': 2, 'forecast_history': 24, 'n_time_series': 7, 'forecast_length': 1, 'num_layer': 1, 'additional_params': {}}, 'dataset_params': {'class': 'default', 'scaled_cols': ['cfs', 'tmpf', 'dwpf'], 'num_workers': 2, 'pin_memory': True, 'training_path': '/content/09405500AZC_flow.csv', 'validation_path': '/content/09405500AZC_flow.csv', 'test_path': '/content/09405500AZC_flow.csv', 'batch_size': 100, 'forecast_test_len': 100, 'forecast_history': 24, 'forecast_length': 1, 'scaler': 'StandardScaler', 'train_start': 1000, 'train_end': 50000, 'valid_start': 50001, 'valid_end': 57000, 'sort_column': 'hour_updated', 'test_start': 57000, 'test_end': 58000, 'target_col': ['cfs'], 'relevant_cols': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1'], 'interpolate': {'method': 'back_forward_generic', 'params': {'relevant_columns': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1']}}, 'feature_param': {'datetime_params': {'hour': 'numerical', 'month': 'numerical'}}}, 'training_params': {'criterion': 'MSE', 'optimizer': 'SGD', 'optim_params': {'lr': 0.001}, 'epochs': 11, 'batch_size': 100}, 'early_stopping': {'patience': 3}, 'GCS': True, 'sweep': True, 'wandb': False, 'forward_params': {}, 'metrics': ['MSE', 'DilateLoss'], 'inference_params': {'datetime_start': '2020-05-31', 'hours_to_forecast': 336, 'num_prediction_samples': 20, 'test_csv_path': '/content/09405500AZC_flow.csv', 'decoder_params': {'decoder_function': 'simple_decode', 'unsqueeze_dim': 1}, 'dataset_params': {'scaled_cols': ['cfs', 'tmpf', 'dwpf'], 'file_path': '/content/09405500AZC_flow.csv', 'sort_column': 'hour_updated', 'scaling': 'StandardScaler', 'forecast_history': 24, 'forecast_length': 1, 'relevant_cols': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1'], 'target_col': ['cfs'], 'interpolate_param': {'method': 'back_forward_generic', 'params': {'relevant_columns': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1']}}, 'feature_params': {'datetime_params': {'hour': 'numerical', 'month': 'numerical'}}}}}\n",
            "Torch is using cuda\n",
            "using 2\n",
            "Pin memory set to true\n",
            "running torch_single_train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/transformer_xl/transformer_bottleneck.py:261: UserWarning:\n",
            "\n",
            "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:770: UserWarning:\n",
            "\n",
            "Using non-full backward hooks on a Module that does not take as input a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:795: UserWarning:\n",
            "\n",
            "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The running loss is: \n",
            "244.00766559448675\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 0\n",
            "0.4979748277438505\n",
            "Computing validation loss\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/custom/dilate_loss.py:44: UserWarning:\n",
            "\n",
            "torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running torch_single_train\n",
            "The running loss is: \n",
            "203.55988573509967\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 1\n",
            "0.4154283382348973\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "181.01143991126446\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 2\n",
            "0.36941110185972337\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "166.73759376670932\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 3\n",
            "0.34028080360552926\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "156.5286649176851\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 4\n",
            "0.3194462549340512\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "148.0272275642492\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 5\n",
            "0.302096382784182\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "141.09273776883492\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 6\n",
            "0.28794436279354063\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "135.0165692535229\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 7\n",
            "0.2755440188847406\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "129.60838309320388\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 8\n",
            "0.26450690427184465\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "124.53762016171822\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 9\n",
            "0.2541584084933025\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "120.14624071860453\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 10\n",
            "0.24519640962980516\n",
            "Computing validation loss\n",
            "Computing validation loss\n",
            "test loss: 792.9073276836425\n",
            "Data saved to: \n",
            "13_May_202103_05AM.json\n",
            "Data saved to: \n",
            "13_May_202103_05AM_model.pth\n",
            "This model is currently forecasting for : 1 targets\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "CSV Path below\n",
            "/content/09405500AZC_flow.csv\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/transformer_xl/transformer_bottleneck.py:261: UserWarning:\n",
            "\n",
            "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "<class 'numpy.ndarray'>\n",
            "transform end tens preform\n",
            "Un-transforming data\n",
            "Current historical dataframe \n",
            "       Unnamed: 0  Unnamed: 0.1  Unnamed: 0_x  ... month       preds    pred_cfs\n",
            "53563       53697         53702       53696.0  ...     5    0.000000    0.000000\n",
            "53564       53698         53703       53697.0  ...     5    0.000000    0.000000\n",
            "53565       53699         53704       53698.0  ...     5    0.000000    0.000000\n",
            "53566       53700         53705       53699.0  ...     5    0.000000    0.000000\n",
            "53567       53701         53706       53700.0  ...     5    0.000000    0.000000\n",
            "...           ...           ...           ...  ...   ...         ...         ...\n",
            "53918       54052         54057       54051.0  ...     6  133.592514  133.592514\n",
            "53919       54053         54058       54052.0  ...     6  134.028244  134.028244\n",
            "53920       54054         54059       54053.0  ...     6  130.781189  130.781189\n",
            "53921       54055         54060       54054.0  ...     6  131.072632  131.072632\n",
            "53922       54056         54061       54055.0  ...     6  128.480881  128.480881\n",
            "\n",
            "[360 rows x 29 columns]\n",
            "begin fixed loss func\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/custom/dilate_loss.py:44: UserWarning:\n",
            "\n",
            "torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "\n",
            "/content/flow-forecast/flood_forecast/transformer_xl/transformer_bottleneck.py:261: UserWarning:\n",
            "\n",
            "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:795: UserWarning:\n",
            "\n",
            "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "plotting with CI now\n",
            "Now plotting final plots\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 10822<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a642a04b7d0547e0944a2c199221e9de",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.26MB of 0.26MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/flow-forecast/wandb/run-20210513_025635-41f487vc/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/flow-forecast/wandb/run-20210513_025635-41f487vc/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>10</td></tr><tr><td>_runtime</td><td>542</td></tr><tr><td>_timestamp</td><td>1620875137</td></tr><tr><td>_step</td><td>55</td></tr><tr><td>loss</td><td>0.2452</td></tr><tr><td>average_prediction_sharpe0</td><td>0.00363</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▄▄▅▅▅▅▆▆▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▃▃▄▄▄▄▄▅████████████████████████</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▃▃▄▄▄▄▄▅████████████████████████</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▄▄▃▃▂▂▂▁▁</td></tr><tr><td>average_prediction_sharpe0</td><td>▁</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 26 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">legendary-sweep-586</strong>: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/41f487vc\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/41f487vc</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: s4zmyfel with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tforecast_history: 24\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tforecast_length: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_heads: 8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumber_encoder_layers: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tq_len: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.30 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.27<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">gentle-sweep-587</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/sweeps/nq46n2lg\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/sweeps/nq46n2lg</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/s4zmyfel\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/s4zmyfel</a><br/>\n",
              "                Run data is saved locally in <code>/content/flow-forecast/wandb/run-20210513_030542-s4zmyfel</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 100, 'dropout': 0.7, 'forecast_history': 24, 'forecast_length': 1, 'lr': 0.001, 'n_heads': 8, 'number_encoder_layers': 2, 'q_len': 1}\n",
            "config made\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "Using Wandb config:\n",
            "{'batch_size': 100, 'dropout': 0.7, 'forecast_history': 24, 'forecast_length': 1, 'lr': 0.001, 'n_heads': 8, 'number_encoder_layers': 2, 'q_len': 1, 'model_name': 'DecoderTransformer', 'model_type': 'PyTorch', 'model_params': {'dropout': 0.7, 'n_embd': 128, 'n_head': 8, 'q_len': 1, 'forecast_history': 24, 'n_time_series': 7, 'forecast_length': 1, 'num_layer': 2, 'additional_params': {}}, 'dataset_params': {'class': 'default', 'scaled_cols': ['cfs', 'tmpf', 'dwpf'], 'num_workers': 2, 'pin_memory': True, 'training_path': '/content/09405500AZC_flow.csv', 'validation_path': '/content/09405500AZC_flow.csv', 'test_path': '/content/09405500AZC_flow.csv', 'batch_size': 100, 'forecast_test_len': 100, 'forecast_history': 24, 'forecast_length': 1, 'scaler': 'StandardScaler', 'train_start': 1000, 'train_end': 50000, 'valid_start': 50001, 'valid_end': 57000, 'sort_column': 'hour_updated', 'test_start': 57000, 'test_end': 58000, 'target_col': ['cfs'], 'relevant_cols': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1'], 'interpolate': {'method': 'back_forward_generic', 'params': {'relevant_columns': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1']}}, 'feature_param': {'datetime_params': {'hour': 'numerical', 'month': 'numerical'}}}, 'training_params': {'criterion': 'MSE', 'optimizer': 'SGD', 'optim_params': {'lr': 0.001}, 'epochs': 11, 'batch_size': 100}, 'early_stopping': {'patience': 3}, 'GCS': True, 'sweep': True, 'wandb': False, 'forward_params': {}, 'metrics': ['MSE', 'DilateLoss'], 'inference_params': {'datetime_start': '2020-05-31', 'hours_to_forecast': 336, 'num_prediction_samples': 20, 'test_csv_path': '/content/09405500AZC_flow.csv', 'decoder_params': {'decoder_function': 'simple_decode', 'unsqueeze_dim': 1}, 'dataset_params': {'scaled_cols': ['cfs', 'tmpf', 'dwpf'], 'file_path': '/content/09405500AZC_flow.csv', 'sort_column': 'hour_updated', 'scaling': 'StandardScaler', 'forecast_history': 24, 'forecast_length': 1, 'relevant_cols': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1'], 'target_col': ['cfs'], 'interpolate_param': {'method': 'back_forward_generic', 'params': {'relevant_columns': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1']}}, 'feature_params': {'datetime_params': {'hour': 'numerical', 'month': 'numerical'}}}}}\n",
            "Torch is using cuda\n",
            "using 2\n",
            "Pin memory set to true\n",
            "running torch_single_train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/transformer_xl/transformer_bottleneck.py:261: UserWarning:\n",
            "\n",
            "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:770: UserWarning:\n",
            "\n",
            "Using non-full backward hooks on a Module that does not take as input a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:795: UserWarning:\n",
            "\n",
            "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The running loss is: \n",
            "316.2581792079436\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 0\n",
            "0.6454248555264155\n",
            "Computing validation loss\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/custom/dilate_loss.py:44: UserWarning:\n",
            "\n",
            "torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running torch_single_train\n",
            "The running loss is: \n",
            "198.85170848714188\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 1\n",
            "0.4058198132390651\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "160.58363245800138\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 2\n",
            "0.32772169889388036\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "143.98985978134442\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 3\n",
            "0.29385685669662126\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "132.76314049609937\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 4\n",
            "0.27094518468591705\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "124.15833996026777\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 5\n",
            "0.25338436726585256\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "116.84553060447797\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 6\n",
            "0.23846026653975097\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "111.24322296201717\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 7\n",
            "0.22702698563676973\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "106.36821240396239\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 8\n",
            "0.21707798449788243\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "102.5545480796136\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 9\n",
            "0.20929499608084406\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "98.88886252307566\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 10\n",
            "0.201814005149134\n",
            "Computing validation loss\n",
            "Computing validation loss\n",
            "test loss: 879.8806644640863\n",
            "Data saved to: \n",
            "13_May_202103_17AM.json\n",
            "Data saved to: \n",
            "13_May_202103_17AM_model.pth\n",
            "This model is currently forecasting for : 1 targets\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "CSV Path below\n",
            "/content/09405500AZC_flow.csv\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/transformer_xl/transformer_bottleneck.py:261: UserWarning:\n",
            "\n",
            "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "<class 'numpy.ndarray'>\n",
            "transform end tens preform\n",
            "Un-transforming data\n",
            "Current historical dataframe \n",
            "       Unnamed: 0  Unnamed: 0.1  Unnamed: 0_x  ... month      preds   pred_cfs\n",
            "53563       53697         53702       53696.0  ...     5   0.000000   0.000000\n",
            "53564       53698         53703       53697.0  ...     5   0.000000   0.000000\n",
            "53565       53699         53704       53698.0  ...     5   0.000000   0.000000\n",
            "53566       53700         53705       53699.0  ...     5   0.000000   0.000000\n",
            "53567       53701         53706       53700.0  ...     5   0.000000   0.000000\n",
            "...           ...           ...           ...  ...   ...        ...        ...\n",
            "53918       54052         54057       54051.0  ...     6 -23.465559 -23.465559\n",
            "53919       54053         54058       54052.0  ...     6 -19.209852 -19.209852\n",
            "53920       54054         54059       54053.0  ...     6 -13.534971 -13.534971\n",
            "53921       54055         54060       54054.0  ...     6 -11.152990 -11.152990\n",
            "53922       54056         54061       54055.0  ...     6  -4.717206  -4.717206\n",
            "\n",
            "[360 rows x 29 columns]\n",
            "begin fixed loss func\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/custom/dilate_loss.py:44: UserWarning:\n",
            "\n",
            "torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "\n",
            "/content/flow-forecast/flood_forecast/transformer_xl/transformer_bottleneck.py:261: UserWarning:\n",
            "\n",
            "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:795: UserWarning:\n",
            "\n",
            "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "plotting with CI now\n",
            "Now plotting final plots\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 11111<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12c9f03fcd7144058d93cbd7d5347ba0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.26MB of 0.26MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/flow-forecast/wandb/run-20210513_030542-s4zmyfel/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/flow-forecast/wandb/run-20210513_030542-s4zmyfel/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>10</td></tr><tr><td>_runtime</td><td>731</td></tr><tr><td>_timestamp</td><td>1620875873</td></tr><tr><td>_step</td><td>55</td></tr><tr><td>loss</td><td>0.20181</td></tr><tr><td>average_prediction_sharpe0</td><td>0.01064</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▄▄▅▅▅▅▆▆▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄████████████████████████</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄████████████████████████</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▄▃▂▂▂▂▁▁▁▁</td></tr><tr><td>average_prediction_sharpe0</td><td>▁</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 26 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">gentle-sweep-587</strong>: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/s4zmyfel\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/s4zmyfel</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: og4sbaw1 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tforecast_history: 24\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tforecast_length: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_heads: 8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumber_encoder_layers: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tq_len: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.30 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.27<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">swift-sweep-588</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/sweeps/nq46n2lg\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/sweeps/nq46n2lg</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/og4sbaw1\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/og4sbaw1</a><br/>\n",
              "                Run data is saved locally in <code>/content/flow-forecast/wandb/run-20210513_031758-og4sbaw1</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 100, 'dropout': 0.7, 'forecast_history': 24, 'forecast_length': 1, 'lr': 0.001, 'n_heads': 8, 'number_encoder_layers': 2, 'q_len': 2}\n",
            "config made\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "Using Wandb config:\n",
            "{'batch_size': 100, 'dropout': 0.7, 'forecast_history': 24, 'forecast_length': 1, 'lr': 0.001, 'n_heads': 8, 'number_encoder_layers': 2, 'q_len': 2, 'model_name': 'DecoderTransformer', 'model_type': 'PyTorch', 'model_params': {'dropout': 0.7, 'n_embd': 128, 'n_head': 8, 'q_len': 2, 'forecast_history': 24, 'n_time_series': 7, 'forecast_length': 1, 'num_layer': 2, 'additional_params': {}}, 'dataset_params': {'class': 'default', 'scaled_cols': ['cfs', 'tmpf', 'dwpf'], 'num_workers': 2, 'pin_memory': True, 'training_path': '/content/09405500AZC_flow.csv', 'validation_path': '/content/09405500AZC_flow.csv', 'test_path': '/content/09405500AZC_flow.csv', 'batch_size': 100, 'forecast_test_len': 100, 'forecast_history': 24, 'forecast_length': 1, 'scaler': 'StandardScaler', 'train_start': 1000, 'train_end': 50000, 'valid_start': 50001, 'valid_end': 57000, 'sort_column': 'hour_updated', 'test_start': 57000, 'test_end': 58000, 'target_col': ['cfs'], 'relevant_cols': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1'], 'interpolate': {'method': 'back_forward_generic', 'params': {'relevant_columns': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1']}}, 'feature_param': {'datetime_params': {'hour': 'numerical', 'month': 'numerical'}}}, 'training_params': {'criterion': 'MSE', 'optimizer': 'SGD', 'optim_params': {'lr': 0.001}, 'epochs': 11, 'batch_size': 100}, 'early_stopping': {'patience': 3}, 'GCS': True, 'sweep': True, 'wandb': False, 'forward_params': {}, 'metrics': ['MSE', 'DilateLoss'], 'inference_params': {'datetime_start': '2020-05-31', 'hours_to_forecast': 336, 'num_prediction_samples': 20, 'test_csv_path': '/content/09405500AZC_flow.csv', 'decoder_params': {'decoder_function': 'simple_decode', 'unsqueeze_dim': 1}, 'dataset_params': {'scaled_cols': ['cfs', 'tmpf', 'dwpf'], 'file_path': '/content/09405500AZC_flow.csv', 'sort_column': 'hour_updated', 'scaling': 'StandardScaler', 'forecast_history': 24, 'forecast_length': 1, 'relevant_cols': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1'], 'target_col': ['cfs'], 'interpolate_param': {'method': 'back_forward_generic', 'params': {'relevant_columns': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1']}}, 'feature_params': {'datetime_params': {'hour': 'numerical', 'month': 'numerical'}}}}}\n",
            "Torch is using cuda\n",
            "using 2\n",
            "Pin memory set to true\n",
            "running torch_single_train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/transformer_xl/transformer_bottleneck.py:261: UserWarning:\n",
            "\n",
            "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:770: UserWarning:\n",
            "\n",
            "Using non-full backward hooks on a Module that does not take as input a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:795: UserWarning:\n",
            "\n",
            "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The running loss is: \n",
            "250.86220863979543\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 0\n",
            "0.5119636911016233\n",
            "Computing validation loss\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/custom/dilate_loss.py:44: UserWarning:\n",
            "\n",
            "torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running torch_single_train\n",
            "The running loss is: \n",
            "230.61977195972577\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 1\n",
            "0.470652595836175\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "211.2560204117326\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 2\n",
            "0.43113473553414816\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "190.30401610583067\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 3\n",
            "0.38837554307312383\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "168.48231017647777\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 4\n",
            "0.3438414493397505\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "149.16130776715\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 5\n",
            "0.30441083217785714\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "135.29303313337732\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 6\n",
            "0.27610823088444353\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "125.8857331816107\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 7\n",
            "0.25690965955430756\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "118.76415093371179\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 8\n",
            "0.2423758182320649\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "112.61789752135519\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 9\n",
            "0.22983244392113303\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "108.12034610740375\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 10\n",
            "0.2206537675661301\n",
            "Computing validation loss\n",
            "Computing validation loss\n",
            "test loss: 866.953901425004\n",
            "Data saved to: \n",
            "13_May_202103_29AM.json\n",
            "Data saved to: \n",
            "13_May_202103_29AM_model.pth\n",
            "This model is currently forecasting for : 1 targets\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "CSV Path below\n",
            "/content/09405500AZC_flow.csv\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/transformer_xl/transformer_bottleneck.py:261: UserWarning:\n",
            "\n",
            "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "<class 'numpy.ndarray'>\n",
            "transform end tens preform\n",
            "Un-transforming data\n",
            "Current historical dataframe \n",
            "       Unnamed: 0  Unnamed: 0.1  Unnamed: 0_x  ... month      preds   pred_cfs\n",
            "53563       53697         53702       53696.0  ...     5   0.000000   0.000000\n",
            "53564       53698         53703       53697.0  ...     5   0.000000   0.000000\n",
            "53565       53699         53704       53698.0  ...     5   0.000000   0.000000\n",
            "53566       53700         53705       53699.0  ...     5   0.000000   0.000000\n",
            "53567       53701         53706       53700.0  ...     5   0.000000   0.000000\n",
            "...           ...           ...           ...  ...   ...        ...        ...\n",
            "53918       54052         54057       54051.0  ...     6  10.085428  10.085428\n",
            "53919       54053         54058       54052.0  ...     6  15.225153  15.225153\n",
            "53920       54054         54059       54053.0  ...     6  19.446230  19.446230\n",
            "53921       54055         54060       54054.0  ...     6  23.582457  23.582457\n",
            "53922       54056         54061       54055.0  ...     6  27.297243  27.297243\n",
            "\n",
            "[360 rows x 29 columns]\n",
            "begin fixed loss func\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/custom/dilate_loss.py:44: UserWarning:\n",
            "\n",
            "torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "\n",
            "/content/flow-forecast/flood_forecast/transformer_xl/transformer_bottleneck.py:261: UserWarning:\n",
            "\n",
            "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:795: UserWarning:\n",
            "\n",
            "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "plotting with CI now\n",
            "Now plotting final plots\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 11400<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d9fd44552b649848e0ce2baab608c80",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.26MB of 0.26MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/flow-forecast/wandb/run-20210513_031758-og4sbaw1/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/flow-forecast/wandb/run-20210513_031758-og4sbaw1/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>10</td></tr><tr><td>_runtime</td><td>733</td></tr><tr><td>_timestamp</td><td>1620876611</td></tr><tr><td>_step</td><td>55</td></tr><tr><td>loss</td><td>0.22065</td></tr><tr><td>average_prediction_sharpe0</td><td>0.01135</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▄▄▅▅▅▅▆▆▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄████████████████████████</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄████████████████████████</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▇▆▅▄▃▂▂▂▁▁</td></tr><tr><td>average_prediction_sharpe0</td><td>▁</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 26 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">swift-sweep-588</strong>: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/og4sbaw1\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/og4sbaw1</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5jg5trzu with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tforecast_history: 24\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tforecast_length: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_heads: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumber_encoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tq_len: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.30 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.27<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">lemon-sweep-589</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/sweeps/nq46n2lg\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/sweeps/nq46n2lg</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/5jg5trzu\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/5jg5trzu</a><br/>\n",
              "                Run data is saved locally in <code>/content/flow-forecast/wandb/run-20210513_033017-5jg5trzu</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 100, 'dropout': 0.7, 'forecast_history': 24, 'forecast_length': 1, 'lr': 0.0001, 'n_heads': 2, 'number_encoder_layers': 1, 'q_len': 1}\n",
            "config made\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "Using Wandb config:\n",
            "{'batch_size': 100, 'dropout': 0.7, 'forecast_history': 24, 'forecast_length': 1, 'lr': 0.0001, 'n_heads': 2, 'number_encoder_layers': 1, 'q_len': 1, 'model_name': 'DecoderTransformer', 'model_type': 'PyTorch', 'model_params': {'dropout': 0.7, 'n_embd': 128, 'n_head': 2, 'q_len': 1, 'forecast_history': 24, 'n_time_series': 7, 'forecast_length': 1, 'num_layer': 1, 'additional_params': {}}, 'dataset_params': {'class': 'default', 'scaled_cols': ['cfs', 'tmpf', 'dwpf'], 'num_workers': 2, 'pin_memory': True, 'training_path': '/content/09405500AZC_flow.csv', 'validation_path': '/content/09405500AZC_flow.csv', 'test_path': '/content/09405500AZC_flow.csv', 'batch_size': 100, 'forecast_test_len': 100, 'forecast_history': 24, 'forecast_length': 1, 'scaler': 'StandardScaler', 'train_start': 1000, 'train_end': 50000, 'valid_start': 50001, 'valid_end': 57000, 'sort_column': 'hour_updated', 'test_start': 57000, 'test_end': 58000, 'target_col': ['cfs'], 'relevant_cols': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1'], 'interpolate': {'method': 'back_forward_generic', 'params': {'relevant_columns': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1']}}, 'feature_param': {'datetime_params': {'hour': 'numerical', 'month': 'numerical'}}}, 'training_params': {'criterion': 'MSE', 'optimizer': 'SGD', 'optim_params': {'lr': 0.0001}, 'epochs': 11, 'batch_size': 100}, 'early_stopping': {'patience': 3}, 'GCS': True, 'sweep': True, 'wandb': False, 'forward_params': {}, 'metrics': ['MSE', 'DilateLoss'], 'inference_params': {'datetime_start': '2020-05-31', 'hours_to_forecast': 336, 'num_prediction_samples': 20, 'test_csv_path': '/content/09405500AZC_flow.csv', 'decoder_params': {'decoder_function': 'simple_decode', 'unsqueeze_dim': 1}, 'dataset_params': {'scaled_cols': ['cfs', 'tmpf', 'dwpf'], 'file_path': '/content/09405500AZC_flow.csv', 'sort_column': 'hour_updated', 'scaling': 'StandardScaler', 'forecast_history': 24, 'forecast_length': 1, 'relevant_cols': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1'], 'target_col': ['cfs'], 'interpolate_param': {'method': 'back_forward_generic', 'params': {'relevant_columns': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1']}}, 'feature_params': {'datetime_params': {'hour': 'numerical', 'month': 'numerical'}}}}}\n",
            "Torch is using cuda\n",
            "using 2\n",
            "Pin memory set to true\n",
            "running torch_single_train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/transformer_xl/transformer_bottleneck.py:261: UserWarning:\n",
            "\n",
            "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:770: UserWarning:\n",
            "\n",
            "Using non-full backward hooks on a Module that does not take as input a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:795: UserWarning:\n",
            "\n",
            "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The running loss is: \n",
            "499.4723946293816\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 0\n",
            "1.019331417610983\n",
            "Computing validation loss\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/custom/dilate_loss.py:44: UserWarning:\n",
            "\n",
            "torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running torch_single_train\n",
            "The running loss is: \n",
            "496.1074168268824\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 1\n",
            "1.0124641159732295\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "492.2534368672641\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 2\n",
            "1.0045988507495185\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "488.05301345302723\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 3\n",
            "0.9960265580674025\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "483.6096142915776\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 4\n",
            "0.9869583965134237\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "477.6579591879854\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 5\n",
            "0.9748121616081334\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "467.60520922974683\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 6\n",
            "0.9542963453668303\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "449.90022579650395\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 7\n",
            "0.9181637261153142\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "420.02614742936566\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 8\n",
            "0.8571962192436035\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "376.41684321896173\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 9\n",
            "0.7681976392223708\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "325.30350517993793\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 10\n",
            "0.663884704448853\n",
            "Computing validation loss\n",
            "Computing validation loss\n",
            "test loss: 825.9826147593558\n",
            "Data saved to: \n",
            "13_May_202103_38AM.json\n",
            "Data saved to: \n",
            "13_May_202103_38AM_model.pth\n",
            "This model is currently forecasting for : 1 targets\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "CSV Path below\n",
            "/content/09405500AZC_flow.csv\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/transformer_xl/transformer_bottleneck.py:261: UserWarning:\n",
            "\n",
            "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "<class 'numpy.ndarray'>\n",
            "transform end tens preform\n",
            "Un-transforming data\n",
            "Current historical dataframe \n",
            "       Unnamed: 0  Unnamed: 0.1  Unnamed: 0_x  ... month       preds    pred_cfs\n",
            "53563       53697         53702       53696.0  ...     5    0.000000    0.000000\n",
            "53564       53698         53703       53697.0  ...     5    0.000000    0.000000\n",
            "53565       53699         53704       53698.0  ...     5    0.000000    0.000000\n",
            "53566       53700         53705       53699.0  ...     5    0.000000    0.000000\n",
            "53567       53701         53706       53700.0  ...     5    0.000000    0.000000\n",
            "...           ...           ...           ...  ...   ...         ...         ...\n",
            "53918       54052         54057       54051.0  ...     6   96.344940   96.344940\n",
            "53919       54053         54058       54052.0  ...     6  100.009888  100.009888\n",
            "53920       54054         54059       54053.0  ...     6   96.228729   96.228729\n",
            "53921       54055         54060       54054.0  ...     6   97.262939   97.262939\n",
            "53922       54056         54061       54055.0  ...     6   95.968513   95.968513\n",
            "\n",
            "[360 rows x 29 columns]\n",
            "begin fixed loss func\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/custom/dilate_loss.py:44: UserWarning:\n",
            "\n",
            "torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "\n",
            "/content/flow-forecast/flood_forecast/transformer_xl/transformer_bottleneck.py:261: UserWarning:\n",
            "\n",
            "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:795: UserWarning:\n",
            "\n",
            "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "plotting with CI now\n",
            "Now plotting final plots\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 11689<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd5ba6beb7d4436da3102cc3500fd998",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.26MB of 0.26MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/flow-forecast/wandb/run-20210513_033017-5jg5trzu/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/flow-forecast/wandb/run-20210513_033017-5jg5trzu/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>10</td></tr><tr><td>_runtime</td><td>532</td></tr><tr><td>_timestamp</td><td>1620877149</td></tr><tr><td>_step</td><td>55</td></tr><tr><td>loss</td><td>0.66388</td></tr><tr><td>average_prediction_sharpe0</td><td>0.0305</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▄▄▅▅▅▅▆▆▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▃▃▄▄▄▄▄▅████████████████████████</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▃▃▄▄▄▄▄▅████████████████████████</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>████▇▇▇▆▅▃▁</td></tr><tr><td>average_prediction_sharpe0</td><td>▁</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 26 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">lemon-sweep-589</strong>: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/5jg5trzu\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/5jg5trzu</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 49jn2vc2 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tforecast_history: 24\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tforecast_length: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_heads: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumber_encoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tq_len: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.30 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.27<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">azure-sweep-590</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/sweeps/nq46n2lg\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/sweeps/nq46n2lg</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/49jn2vc2\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/49jn2vc2</a><br/>\n",
              "                Run data is saved locally in <code>/content/flow-forecast/wandb/run-20210513_033916-49jn2vc2</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 100, 'dropout': 0.7, 'forecast_history': 24, 'forecast_length': 1, 'lr': 0.0001, 'n_heads': 2, 'number_encoder_layers': 1, 'q_len': 2}\n",
            "config made\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "Using Wandb config:\n",
            "{'batch_size': 100, 'dropout': 0.7, 'forecast_history': 24, 'forecast_length': 1, 'lr': 0.0001, 'n_heads': 2, 'number_encoder_layers': 1, 'q_len': 2, 'model_name': 'DecoderTransformer', 'model_type': 'PyTorch', 'model_params': {'dropout': 0.7, 'n_embd': 128, 'n_head': 2, 'q_len': 2, 'forecast_history': 24, 'n_time_series': 7, 'forecast_length': 1, 'num_layer': 1, 'additional_params': {}}, 'dataset_params': {'class': 'default', 'scaled_cols': ['cfs', 'tmpf', 'dwpf'], 'num_workers': 2, 'pin_memory': True, 'training_path': '/content/09405500AZC_flow.csv', 'validation_path': '/content/09405500AZC_flow.csv', 'test_path': '/content/09405500AZC_flow.csv', 'batch_size': 100, 'forecast_test_len': 100, 'forecast_history': 24, 'forecast_length': 1, 'scaler': 'StandardScaler', 'train_start': 1000, 'train_end': 50000, 'valid_start': 50001, 'valid_end': 57000, 'sort_column': 'hour_updated', 'test_start': 57000, 'test_end': 58000, 'target_col': ['cfs'], 'relevant_cols': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1'], 'interpolate': {'method': 'back_forward_generic', 'params': {'relevant_columns': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1']}}, 'feature_param': {'datetime_params': {'hour': 'numerical', 'month': 'numerical'}}}, 'training_params': {'criterion': 'MSE', 'optimizer': 'SGD', 'optim_params': {'lr': 0.0001}, 'epochs': 11, 'batch_size': 100}, 'early_stopping': {'patience': 3}, 'GCS': True, 'sweep': True, 'wandb': False, 'forward_params': {}, 'metrics': ['MSE', 'DilateLoss'], 'inference_params': {'datetime_start': '2020-05-31', 'hours_to_forecast': 336, 'num_prediction_samples': 20, 'test_csv_path': '/content/09405500AZC_flow.csv', 'decoder_params': {'decoder_function': 'simple_decode', 'unsqueeze_dim': 1}, 'dataset_params': {'scaled_cols': ['cfs', 'tmpf', 'dwpf'], 'file_path': '/content/09405500AZC_flow.csv', 'sort_column': 'hour_updated', 'scaling': 'StandardScaler', 'forecast_history': 24, 'forecast_length': 1, 'relevant_cols': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1'], 'target_col': ['cfs'], 'interpolate_param': {'method': 'back_forward_generic', 'params': {'relevant_columns': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1']}}, 'feature_params': {'datetime_params': {'hour': 'numerical', 'month': 'numerical'}}}}}\n",
            "Torch is using cuda\n",
            "using 2\n",
            "Pin memory set to true\n",
            "running torch_single_train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/transformer_xl/transformer_bottleneck.py:261: UserWarning:\n",
            "\n",
            "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:770: UserWarning:\n",
            "\n",
            "Using non-full backward hooks on a Module that does not take as input a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:795: UserWarning:\n",
            "\n",
            "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The running loss is: \n",
            "465.5504508697486\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 0\n",
            "0.9501029609586706\n",
            "Computing validation loss\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/custom/dilate_loss.py:44: UserWarning:\n",
            "\n",
            "torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running torch_single_train\n",
            "The running loss is: \n",
            "441.06510167277884\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 1\n",
            "0.9001328605566915\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "399.1181081470568\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 2\n",
            "0.814526751320524\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "343.5766228819266\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 3\n",
            "0.7011767813916869\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "285.10794128570706\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 4\n",
            "0.5818529413994021\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "236.21840649936348\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 5\n",
            "0.4820783806109459\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "203.07761995121837\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 6\n",
            "0.41444412234942524\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "184.6420087729348\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 7\n",
            "0.37682042606721383\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "175.3564535434125\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 8\n",
            "0.35787031335390307\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "170.6240433973726\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 9\n",
            "0.3482123334640257\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "167.71312955959002\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 10\n",
            "0.34227169297875515\n",
            "Computing validation loss\n",
            "Computing validation loss\n",
            "test loss: 702.5145037956536\n",
            "Data saved to: \n",
            "13_May_202103_47AM.json\n",
            "Data saved to: \n",
            "13_May_202103_47AM_model.pth\n",
            "This model is currently forecasting for : 1 targets\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "CSV Path below\n",
            "/content/09405500AZC_flow.csv\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/transformer_xl/transformer_bottleneck.py:261: UserWarning:\n",
            "\n",
            "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "<class 'numpy.ndarray'>\n",
            "transform end tens preform\n",
            "Un-transforming data\n",
            "Current historical dataframe \n",
            "       Unnamed: 0  Unnamed: 0.1  Unnamed: 0_x  ... month      preds   pred_cfs\n",
            "53563       53697         53702       53696.0  ...     5   0.000000   0.000000\n",
            "53564       53698         53703       53697.0  ...     5   0.000000   0.000000\n",
            "53565       53699         53704       53698.0  ...     5   0.000000   0.000000\n",
            "53566       53700         53705       53699.0  ...     5   0.000000   0.000000\n",
            "53567       53701         53706       53700.0  ...     5   0.000000   0.000000\n",
            "...           ...           ...           ...  ...   ...        ...        ...\n",
            "53918       54052         54057       54051.0  ...     6  68.063194  68.063194\n",
            "53919       54053         54058       54052.0  ...     6  63.693825  63.693825\n",
            "53920       54054         54059       54053.0  ...     6  61.622005  61.622005\n",
            "53921       54055         54060       54054.0  ...     6  64.353493  64.353493\n",
            "53922       54056         54061       54055.0  ...     6  68.466751  68.466751\n",
            "\n",
            "[360 rows x 29 columns]\n",
            "begin fixed loss func\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/custom/dilate_loss.py:44: UserWarning:\n",
            "\n",
            "torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "\n",
            "/content/flow-forecast/flood_forecast/transformer_xl/transformer_bottleneck.py:261: UserWarning:\n",
            "\n",
            "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:795: UserWarning:\n",
            "\n",
            "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "plotting with CI now\n",
            "Now plotting final plots\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 11978<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5273b720fc684a9b9086ac737fe56e82",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.25MB of 0.26MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=0.96905363912…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/flow-forecast/wandb/run-20210513_033916-49jn2vc2/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/flow-forecast/wandb/run-20210513_033916-49jn2vc2/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>10</td></tr><tr><td>_runtime</td><td>519</td></tr><tr><td>_timestamp</td><td>1620877675</td></tr><tr><td>_step</td><td>55</td></tr><tr><td>loss</td><td>0.34227</td></tr><tr><td>average_prediction_sharpe0</td><td>0.21929</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▄▄▅▅▅▅▆▆▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▃▃▄▄▄▄▄▅████████████████████████</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▃▃▄▄▄▄▄▅████████████████████████</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▇▆▅▄▃▂▁▁▁▁</td></tr><tr><td>average_prediction_sharpe0</td><td>▁</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 26 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">azure-sweep-590</strong>: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/49jn2vc2\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/49jn2vc2</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l3h48gu4 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tforecast_history: 24\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tforecast_length: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_heads: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumber_encoder_layers: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tq_len: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.30 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.27<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">resilient-sweep-591</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/sweeps/nq46n2lg\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/sweeps/nq46n2lg</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/l3h48gu4\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/l3h48gu4</a><br/>\n",
              "                Run data is saved locally in <code>/content/flow-forecast/wandb/run-20210513_034804-l3h48gu4</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 100, 'dropout': 0.7, 'forecast_history': 24, 'forecast_length': 1, 'lr': 0.0001, 'n_heads': 2, 'number_encoder_layers': 2, 'q_len': 1}\n",
            "config made\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "Using Wandb config:\n",
            "{'batch_size': 100, 'dropout': 0.7, 'forecast_history': 24, 'forecast_length': 1, 'lr': 0.0001, 'n_heads': 2, 'number_encoder_layers': 2, 'q_len': 1, 'model_name': 'DecoderTransformer', 'model_type': 'PyTorch', 'model_params': {'dropout': 0.7, 'n_embd': 128, 'n_head': 2, 'q_len': 1, 'forecast_history': 24, 'n_time_series': 7, 'forecast_length': 1, 'num_layer': 2, 'additional_params': {}}, 'dataset_params': {'class': 'default', 'scaled_cols': ['cfs', 'tmpf', 'dwpf'], 'num_workers': 2, 'pin_memory': True, 'training_path': '/content/09405500AZC_flow.csv', 'validation_path': '/content/09405500AZC_flow.csv', 'test_path': '/content/09405500AZC_flow.csv', 'batch_size': 100, 'forecast_test_len': 100, 'forecast_history': 24, 'forecast_length': 1, 'scaler': 'StandardScaler', 'train_start': 1000, 'train_end': 50000, 'valid_start': 50001, 'valid_end': 57000, 'sort_column': 'hour_updated', 'test_start': 57000, 'test_end': 58000, 'target_col': ['cfs'], 'relevant_cols': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1'], 'interpolate': {'method': 'back_forward_generic', 'params': {'relevant_columns': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1']}}, 'feature_param': {'datetime_params': {'hour': 'numerical', 'month': 'numerical'}}}, 'training_params': {'criterion': 'MSE', 'optimizer': 'SGD', 'optim_params': {'lr': 0.0001}, 'epochs': 11, 'batch_size': 100}, 'early_stopping': {'patience': 3}, 'GCS': True, 'sweep': True, 'wandb': False, 'forward_params': {}, 'metrics': ['MSE', 'DilateLoss'], 'inference_params': {'datetime_start': '2020-05-31', 'hours_to_forecast': 336, 'num_prediction_samples': 20, 'test_csv_path': '/content/09405500AZC_flow.csv', 'decoder_params': {'decoder_function': 'simple_decode', 'unsqueeze_dim': 1}, 'dataset_params': {'scaled_cols': ['cfs', 'tmpf', 'dwpf'], 'file_path': '/content/09405500AZC_flow.csv', 'sort_column': 'hour_updated', 'scaling': 'StandardScaler', 'forecast_history': 24, 'forecast_length': 1, 'relevant_cols': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1'], 'target_col': ['cfs'], 'interpolate_param': {'method': 'back_forward_generic', 'params': {'relevant_columns': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1']}}, 'feature_params': {'datetime_params': {'hour': 'numerical', 'month': 'numerical'}}}}}\n",
            "Torch is using cuda\n",
            "using 2\n",
            "Pin memory set to true\n",
            "running torch_single_train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/transformer_xl/transformer_bottleneck.py:261: UserWarning:\n",
            "\n",
            "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:770: UserWarning:\n",
            "\n",
            "Using non-full backward hooks on a Module that does not take as input a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:795: UserWarning:\n",
            "\n",
            "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The running loss is: \n",
            "489.69620586931705\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 0\n",
            "0.999380011978198\n",
            "Computing validation loss\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/custom/dilate_loss.py:44: UserWarning:\n",
            "\n",
            "torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running torch_single_train\n",
            "The running loss is: \n",
            "486.0391985331662\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 1\n",
            "0.9919167317003392\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "480.4871403123252\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 2\n",
            "0.9805860006373984\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "470.861815948796\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 3\n",
            "0.9609424815281551\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "453.36638148513157\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 4\n",
            "0.9252375132349624\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "422.6043825238012\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 5\n",
            "0.8624579235179616\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "374.3938704582397\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 6\n",
            "0.7640691233841627\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "315.4817019284237\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 7\n",
            "0.6438402080171912\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "262.30451796925627\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 8\n",
            "0.5353153427944005\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "225.57849918934517\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 9\n",
            "0.4603642840598881\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "205.95607127877884\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 10\n",
            "0.42031851281383437\n",
            "Computing validation loss\n",
            "Computing validation loss\n",
            "test loss: 711.3614258132875\n",
            "Data saved to: \n",
            "13_May_202103_59AM.json\n",
            "Data saved to: \n",
            "13_May_202103_59AM_model.pth\n",
            "This model is currently forecasting for : 1 targets\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "CSV Path below\n",
            "/content/09405500AZC_flow.csv\n",
            "Add debugging crap below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/transformer_xl/transformer_bottleneck.py:261: UserWarning:\n",
            "\n",
            "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "Add debugging crap below\n",
            "<class 'numpy.ndarray'>\n",
            "transform end tens preform\n",
            "Un-transforming data\n",
            "Current historical dataframe \n",
            "       Unnamed: 0  Unnamed: 0.1  Unnamed: 0_x  ... month      preds   pred_cfs\n",
            "53563       53697         53702       53696.0  ...     5   0.000000   0.000000\n",
            "53564       53698         53703       53697.0  ...     5   0.000000   0.000000\n",
            "53565       53699         53704       53698.0  ...     5   0.000000   0.000000\n",
            "53566       53700         53705       53699.0  ...     5   0.000000   0.000000\n",
            "53567       53701         53706       53700.0  ...     5   0.000000   0.000000\n",
            "...           ...           ...           ...  ...   ...        ...        ...\n",
            "53918       54052         54057       54051.0  ...     6  88.611145  88.611145\n",
            "53919       54053         54058       54052.0  ...     6  75.139893  75.139893\n",
            "53920       54054         54059       54053.0  ...     6  75.687012  75.687012\n",
            "53921       54055         54060       54054.0  ...     6  76.320480  76.320480\n",
            "53922       54056         54061       54055.0  ...     6  64.430687  64.430687\n",
            "\n",
            "[360 rows x 29 columns]\n",
            "begin fixed loss func\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/custom/dilate_loss.py:44: UserWarning:\n",
            "\n",
            "torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "\n",
            "/content/flow-forecast/flood_forecast/transformer_xl/transformer_bottleneck.py:261: UserWarning:\n",
            "\n",
            "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:795: UserWarning:\n",
            "\n",
            "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: LayerNorm\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "Warning: unrecognized nn.Module: Conv1D\n",
            "plotting with CI now\n",
            "Now plotting final plots\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 12267<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9424d5cac7184d28983f2819a5c004ba",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.26MB of 0.26MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/flow-forecast/wandb/run-20210513_034804-l3h48gu4/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/flow-forecast/wandb/run-20210513_034804-l3h48gu4/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>10</td></tr><tr><td>_runtime</td><td>716</td></tr><tr><td>_timestamp</td><td>1620878400</td></tr><tr><td>_step</td><td>55</td></tr><tr><td>loss</td><td>0.42032</td></tr><tr><td>average_prediction_sharpe0</td><td>0.04263</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▄▄▅▅▅▅▆▆▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄████████████████████████</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄████████████████████████</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>████▇▆▅▄▂▁▁</td></tr><tr><td>average_prediction_sharpe0</td><td>▁</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 26 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">resilient-sweep-591</strong>: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/l3h48gu4\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/l3h48gu4</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8xwo45af with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tforecast_history: 24\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tforecast_length: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_heads: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnumber_encoder_layers: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tq_len: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.30 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.27<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">feasible-sweep-592</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/sweeps/nq46n2lg\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/sweeps/nq46n2lg</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/8xwo45af\" target=\"_blank\">https://wandb.ai/igodfried/github_aistream-peelout_flow-forecast/runs/8xwo45af</a><br/>\n",
              "                Run data is saved locally in <code>/content/flow-forecast/wandb/run-20210513_040006-8xwo45af</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': 100, 'dropout': 0.7, 'forecast_history': 24, 'forecast_length': 1, 'lr': 0.0001, 'n_heads': 2, 'number_encoder_layers': 2, 'q_len': 2}\n",
            "config made\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "interpolate should be below\n",
            "Running code to add temporal features\n",
            "Created datetime feature columns are: \n",
            "['hour', 'month']\n",
            "Now loading /content/09405500AZC_flow.csv\n",
            "scaling now\n",
            "Using Wandb config:\n",
            "{'batch_size': 100, 'dropout': 0.7, 'forecast_history': 24, 'forecast_length': 1, 'lr': 0.0001, 'n_heads': 2, 'number_encoder_layers': 2, 'q_len': 2, 'model_name': 'DecoderTransformer', 'model_type': 'PyTorch', 'model_params': {'dropout': 0.7, 'n_embd': 128, 'n_head': 2, 'q_len': 2, 'forecast_history': 24, 'n_time_series': 7, 'forecast_length': 1, 'num_layer': 2, 'additional_params': {}}, 'dataset_params': {'class': 'default', 'scaled_cols': ['cfs', 'tmpf', 'dwpf'], 'num_workers': 2, 'pin_memory': True, 'training_path': '/content/09405500AZC_flow.csv', 'validation_path': '/content/09405500AZC_flow.csv', 'test_path': '/content/09405500AZC_flow.csv', 'batch_size': 100, 'forecast_test_len': 100, 'forecast_history': 24, 'forecast_length': 1, 'scaler': 'StandardScaler', 'train_start': 1000, 'train_end': 50000, 'valid_start': 50001, 'valid_end': 57000, 'sort_column': 'hour_updated', 'test_start': 57000, 'test_end': 58000, 'target_col': ['cfs'], 'relevant_cols': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1'], 'interpolate': {'method': 'back_forward_generic', 'params': {'relevant_columns': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1']}}, 'feature_param': {'datetime_params': {'hour': 'numerical', 'month': 'numerical'}}}, 'training_params': {'criterion': 'MSE', 'optimizer': 'SGD', 'optim_params': {'lr': 0.0001}, 'epochs': 11, 'batch_size': 100}, 'early_stopping': {'patience': 3}, 'GCS': True, 'sweep': True, 'wandb': False, 'forward_params': {}, 'metrics': ['MSE', 'DilateLoss'], 'inference_params': {'datetime_start': '2020-05-31', 'hours_to_forecast': 336, 'num_prediction_samples': 20, 'test_csv_path': '/content/09405500AZC_flow.csv', 'decoder_params': {'decoder_function': 'simple_decode', 'unsqueeze_dim': 1}, 'dataset_params': {'scaled_cols': ['cfs', 'tmpf', 'dwpf'], 'file_path': '/content/09405500AZC_flow.csv', 'sort_column': 'hour_updated', 'scaling': 'StandardScaler', 'forecast_history': 24, 'forecast_length': 1, 'relevant_cols': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1'], 'target_col': ['cfs'], 'interpolate_param': {'method': 'back_forward_generic', 'params': {'relevant_columns': ['cfs', 'tmpf', 'p01m', 'dwpf', 'p01m_rolling1']}}, 'feature_params': {'datetime_params': {'hour': 'numerical', 'month': 'numerical'}}}}}\n",
            "Torch is using cuda\n",
            "using 2\n",
            "Pin memory set to true\n",
            "running torch_single_train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/transformer_xl/transformer_bottleneck.py:261: UserWarning:\n",
            "\n",
            "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:770: UserWarning:\n",
            "\n",
            "Using non-full backward hooks on a Module that does not take as input a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:795: UserWarning:\n",
            "\n",
            "Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The running loss is: \n",
            "481.43265039735707\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 0\n",
            "0.9825156130558308\n",
            "Computing validation loss\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/flow-forecast/flood_forecast/custom/dilate_loss.py:44: UserWarning:\n",
            "\n",
            "torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running torch_single_train\n",
            "The running loss is: \n",
            "465.3900610161363\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 1\n",
            "0.9497756347268088\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "442.88055952475406\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 2\n",
            "0.9038378765811308\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "407.05179617065005\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 3\n",
            "0.8307179513686735\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "355.556054309709\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 4\n",
            "0.7256246006320591\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "296.49698159936816\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 5\n",
            "0.6050958808150371\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "244.8740678220056\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 6\n",
            "0.4997429955551135\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "210.65603002579883\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 7\n",
            "0.42991026535877314\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "192.91851434740238\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 8\n",
            "0.39371125377020894\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "184.73589262901805\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 9\n",
            "0.37701202577350623\n",
            "Computing validation loss\n",
            "running torch_single_train\n",
            "The running loss is: \n",
            "180.46351194294402\n",
            "The number of items in train is: 490\n",
            "The loss for epoch 10\n",
            "0.3682928815162123\n",
            "Computing validation loss\n",
            "Computing validation loss\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfxQh1-0T047"
      },
      "source": [
        "import pandas as pd \n",
        "df = pd.read_csv(\"/content/joined_final_3/09406000AZC_flow.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lSeUUGyWpjZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ada49ef-0604-40d6-dad3-a5b45194a5a7"
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.8.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8DSpabKWp7Q"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vr5H_naS5PPV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}